{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Revelio labs and Audit Analytics data, and built rest of variables\n",
    "* Jie XIA, SUSTech\n",
    "* 2025-02-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dataset\n",
    "* Panel dataset built from revelio labs\n",
    "  * `revelio` is sample include auditors who have ever worked in multiple offices or places\n",
    "  * `revelio_filtered` is sample exclude auditors who have ever worked in multiple offices or places\n",
    "* Panel dataset Built from Audit Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "revelio_path = r\"E:\\USA auditor turnover data\\turnover data\\office-year_auditor_turnover_us.csv\"\n",
    "revelio_filtered_path = r\"E:\\USA auditor turnover data\\turnover data\\office-year_auditor_turnover_us_filtered.csv\"\n",
    "aa_path = r\"e:\\USA auditor turnover data\\Audit Analytics data\\office-year us auditor variables from AA data.csv\"\n",
    "\n",
    "print(\"Start to load in csv file\")\n",
    "df_revelio = pd.read_csv(revelio_path, engine='pyarrow')\n",
    "df_revelio_filtered = pd.read_csv(revelio_filtered_path, engine='pyarrow')\n",
    "df_aa = pd.read_csv(aa_path, engine='pyarrow')\n",
    "print(\"Files loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_revelio.columns)\n",
    "#print(df_aa.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_revelio.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_aa.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merge Revelio and AA variables\n",
    "* Merge dataset based on `office_key_location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revelio['office_key_location'] = df_revelio['office_key_location'].astype(str)\n",
    "df_revelio_filtered['office_key_location'] = df_revelio_filtered['office_key_location'].astype(str)\n",
    "df_revelio['year'] = df_revelio['year'].astype(int)\n",
    "df_revelio_filtered['year'] = df_revelio_filtered['year'].astype(int)\n",
    "\n",
    "df_aa['office_key_location'] = df_aa['office_key_location'].astype(str)\n",
    "df_aa['FY_IC_OP'] = df_aa['FY_IC_OP'].astype(int)\n",
    "\n",
    "print(f\"There are {df_revelio['office_key_location'].nunique()} office in revelio\")\n",
    "print(f\"There are {df_revelio_filtered['office_key_location'].nunique()} office in revelio_filtered\")\n",
    "print(f\"There are {df_aa['office_key_location'].nunique()} office in aa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For variables in aa data, create offices's value from 2001 to 2003 base on offices' values in 2004, if they do not exist.\n",
    "* And create a indicator column `copy_2004_indicator` to indicate these offices sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Add a 'copy_value' column to mark original records as 0.\n",
    "df_aa['copy_2004_indicator'] = 0\n",
    "\n",
    "# Define the target years that need to be filled in (the years that are missing).\n",
    "target_years = [2001, 2002, 2003]\n",
    "\n",
    "# Extract the data for 2004 and, for each office, take the first record \n",
    "df_aa_2004 = df_aa[df_aa['FY_IC_OP'] == 2004].drop_duplicates(subset='office_key_location')\n",
    "\n",
    "# List to store rows that need to be added for the missing years.\n",
    "rows_to_add = []\n",
    "\n",
    "# For each office from 2004:\n",
    "for _, row in df_aa_2004.iterrows():\n",
    "    office = row['office_key_location']\n",
    "    # Identify the years (from 2001 to 2003) that already have records for this office.\n",
    "    existing_years = df_aa.loc[\n",
    "        (df_aa['office_key_location'] == office) & (df_aa['FY_IC_OP'].isin(target_years)),\n",
    "        'FY_IC_OP'\n",
    "    ].unique().tolist()\n",
    "    # Determine the missing years.\n",
    "    missing_years = set(target_years) - set(existing_years)\n",
    "    \n",
    "    # For each missing year, duplicate the 2004 record, update the year, and set copy_value to 1.\n",
    "    for yr in missing_years:\n",
    "        new_row = row.copy()\n",
    "        new_row['FY_IC_OP'] = yr\n",
    "        new_row['copy_2004_indicator'] = 1\n",
    "        rows_to_add.append(new_row)\n",
    "\n",
    "# If there are rows to add, convert them to a DataFrame and concatenate with the original df_aa.\n",
    "if rows_to_add:\n",
    "    df_add = pd.DataFrame(rows_to_add)\n",
    "    df_aa_extended = pd.concat([df_aa, df_add], ignore_index=True)\n",
    "else:\n",
    "    df_aa_extended = df_aa.copy()\n",
    "\n",
    "# Sort the extended DataFrame by office_key_location and FY_IC_OP, then reset the index.\n",
    "df_aa_extended = df_aa_extended.sort_values(by=['office_key_location', 'FY_IC_OP']).reset_index(drop=True)\n",
    "\n",
    "# Output statistics.\n",
    "num_offices_2004 = df_aa[df_aa['FY_IC_OP'] == 2004]['office_key_location'].nunique()\n",
    "print(f\"There are {num_offices_2004} office samples in 2004\")\n",
    "print(\"Number of rows in the extended df_aa:\", df_aa_extended.shape[0])\n",
    "\n",
    "# Display a sample of the extended data.\n",
    "print(df_aa_extended.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merge the revelio and aa data based on `office_key_location` and `year`(`FY_IC_OP`)\n",
    "* Print the description of merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasgui import show\n",
    "\n",
    "def merge_dataframe(df_revelio, df_aa):\n",
    "    # 1. Filter Revelio data to include only records from 1990 onwards and count rows per year.\n",
    "    revelio_filtered_year = df_revelio[df_revelio['year'] >= 1990]\n",
    "    revelio_year_counts = revelio_filtered_year.groupby('year').size().reset_index(name='revelio_count')\n",
    "    print(\"Revelio row counts for years from 1990 onwards:\")\n",
    "    print(revelio_year_counts)\n",
    "    \n",
    "    # 2. Count the number of records per year in the AA data.\n",
    "    aa_year_counts = df_aa.groupby('FY_IC_OP').size().reset_index(name='aa_count')\n",
    "    print(\"AA row counts per year:\")\n",
    "    print(aa_year_counts)\n",
    "    \n",
    "    # 3. Merge the original Revelio data with AA data using office_key_location and year.\n",
    "    #    The merge is done as an outer join to allow inspection of merge results.\n",
    "    df_merge = df_revelio.merge(\n",
    "        df_aa,\n",
    "        left_on=['office_key_location', 'year'], \n",
    "        right_on=['office_key_location', 'FY_IC_OP'],\n",
    "        how='outer',\n",
    "        indicator=True\n",
    "    )\n",
    "\n",
    "    # Print overall merge status using the _merge column.\n",
    "    merge_report = df_merge['_merge'].value_counts()\n",
    "    print(\"Overall merge status:\")\n",
    "    print(merge_report)\n",
    "\n",
    "    # Count the number of merged records (i.e., records present in both datasets) for each year.\n",
    "    yearly_both = (\n",
    "        df_merge[df_merge['_merge'] == 'both']\n",
    "        .groupby('year')\n",
    "        .size()\n",
    "        .reset_index(name='both_count')\n",
    "    )\n",
    "    print(\"Merged (both) record counts per year:\")\n",
    "    print(yearly_both)\n",
    "    \n",
    "    # Optionally, keep only the records that successfully merged from both datasets.\n",
    "    df_merge = df_merge[df_merge['_merge'] == 'both']\n",
    "    # Drop the merge indicator and redundant FY_IC_OP column.\n",
    "    df_merge = df_merge.drop(columns=['_merge', 'FY_IC_OP'])\n",
    "\n",
    "    return df_merge\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Start to merge Revelio with AA data\")\n",
    "    df_office_year = merge_dataframe(df_revelio, df_aa_extended)\n",
    "    df_office_year.to_csv(r\"E:\\USA auditor turnover data\\result data\\revelio_aa_merge.csv\", index=False)\n",
    "    \n",
    "    print(\"Start to merge filtered Revelio with AA data\")\n",
    "    df_office_year_filtered = merge_dataframe(df_revelio_filtered, df_aa_extended)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reset the gap_indicator_revelio_office\n",
    "  * Because when generate gap_indicator_revelio_office, we use the whole year range. However, now the year range is deceased to 2001. Therefore, we need to reset the gap of office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Reset indicators to 0\n",
    "df_office_year['gap_indicator_revelio'] = 0\n",
    "df_office_year_filtered['gap_indicator_revelio'] = 0\n",
    "df_office_year['gap_indicator_aa'] = 0\n",
    "df_office_year_filtered['gap_indicator_aa'] = 0\n",
    "\n",
    "# Step 2: Recalculate based on row indicators\n",
    "\n",
    "df_office_year.loc[df_office_year.groupby('office_id')['gap_indicator_revelio_row'].transform(lambda x: (x == 1).any()), 'gap_indicator_revelio'] = 1\n",
    "df_office_year_filtered.loc[df_office_year_filtered.groupby('office_id')['gap_indicator_revelio_row'].transform(lambda x: (x == 1).any()), 'gap_indicator_revelio'] = 1\n",
    "\n",
    "df_office_year.loc[df_office_year.groupby('office_id')['gap_indicator_aa_row'].transform(lambda x: (x == 1).any()), 'gap_indicator_aa'] = 1\n",
    "df_office_year_filtered.loc[df_office_year_filtered.groupby('office_id')['gap_indicator_aa_row'].transform(lambda x: (x == 1).any()), 'gap_indicator_aa'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Manually check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_office_year_check = df_office_year.sort_values(by=['office_id', 'year'])\n",
    "\n",
    "path = r\"E:\\USA auditor turnover data\\result data\\office_year_panel_for_check_gap_reset.csv\"\n",
    "\n",
    "df_office_year_check.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for incorrect `gap_indicator_revelio`\n",
    "incorrect_revelio = df_office_year.groupby('office_id').filter(\n",
    "    lambda g: (g['gap_indicator_revelio_row'] == 0).all() and (g['gap_indicator_revelio'].iloc[0] == 1)\n",
    ")\n",
    "\n",
    "# Check for incorrect `gap_indicator_aa`\n",
    "incorrect_aa = df_office_year.groupby('office_id').filter(\n",
    "    lambda g: (g['gap_indicator_aa_row'] == 0).all() and (g['gap_indicator_aa'].iloc[0] == 1)\n",
    ")\n",
    "\n",
    "# Print the number of incorrect cases\n",
    "print(f\"Number of incorrect `gap_indicator_revelio`: {len(incorrect_revelio['office_id'].unique())}\")\n",
    "print(f\"Number of incorrect `gap_indicator_aa`: {len(incorrect_aa['office_id'].unique())}\")\n",
    "\n",
    "# Show a few examples for debugging\n",
    "print(\"Incorrect `gap_indicator_revelio` examples:\")\n",
    "print(incorrect_revelio[['office_id', 'year', 'gap_indicator_revelio_row', 'gap_indicator_revelio']].drop_duplicates().head(10))\n",
    "\n",
    "print(\"Incorrect `gap_indicator_aa` examples:\")\n",
    "print(incorrect_aa[['office_id', 'year', 'gap_indicator_aa_row', 'gap_indicator_aa']].drop_duplicates().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Build office-level variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute LARGE_OFFICE Indicator:\n",
    "\n",
    "   * Calculate the median office size (using OFFICE_SIZE) for each metro_id and year.\n",
    "   * Create a new indicator, LARGE_OFFICE, which is set to 1 if an office's OFFICE_SIZE is greater than the computed median, and 0 otherwise.\n",
    "2. Compute MARKET_SHARE Indicator:\n",
    "\n",
    "   * For each metro_id and year, sum the OFFICE_SIZE of all offices flagged as Big 4 (BIG4_flag==1) to determine the total number of Big 4 clients (total_big4_clients).\n",
    "   * Merge this total back into the main DataFrame, filling missing values with 0.\n",
    "   * Compute MARKET_SHARE as the ratio of an office's OFFICE_SIZE to total_big4_clients, defaulting to 0 if no Big 4 clients are present.\n",
    "3. Return the Updated DataFrame:\n",
    "\n",
    "   * The function returns the DataFrame with the newly computed indicators, which are then applied to both full and filtered samples, and the first few rows are printed for verification.\n",
    "\n",
    "\n",
    "* **Variables definitions:**\n",
    "  * $\\text{LARGE\\_OFFICE} = \\text{if an audit office’s size is greater than the sample median in an MSA}$\n",
    "  * $\\text{MARKET\\_SHARE} = \\cfrac{\\text{Total number of audit clients in an office in a year}}{\\text{Total number of audit clients for all Big 4 offices in the same MSA in a year}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_indicators(df_merge):\n",
    "    \"\"\"\n",
    "    Computes two new indicators:\n",
    "      1. LARGE_OFFICE: 1 if an office's size (OFFICE_SIZE) is greater than the median \n",
    "         office size for its MSA (identified by metro_id) in that year.\n",
    "      2. MARKET_SHARE: OFFICE_SIZE divided by the total OFFICE_SIZE of all Big 4 offices \n",
    "         (BIG4_flag==1) in the same MSA and year.\n",
    "    \"\"\"\n",
    "    # ---------------------------\n",
    "    # LARGE_OFFICE Calculation\n",
    "    # ---------------------------\n",
    "    # Compute the median office size (using OFFICE_SIZE) for each metro_id and year.\n",
    "    df_merge['median_office_size'] = df_merge.groupby(['metro_id', 'year'])['OFFICE_SIZE'].transform('median')\n",
    "    # Set LARGE_OFFICE = 1 if OFFICE_SIZE > median_office_size, else 0.\n",
    "    df_merge['LARGE_OFFICE'] = (df_merge['OFFICE_SIZE'] > df_merge['median_office_size']).astype(int)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # MARKET_SHARE Calculation\n",
    "    # ---------------------------\n",
    "    # First, for each metro_id and year, compute total OFFICE_SIZE for all Big 4 offices.\n",
    "    # We filter rows with BIG4_flag==1 and group by metro_id and year.\n",
    "    big4_totals = (\n",
    "        df_merge[df_merge['BIG4_flag'] == 1]\n",
    "        .groupby(['metro_id', 'year'])['OFFICE_SIZE']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={'OFFICE_SIZE': 'total_big4_clients'})\n",
    "    )\n",
    "    \n",
    "    # Merge the total Big 4 clients info back into df_merge.\n",
    "    df_merge = df_merge.merge(big4_totals, on=['metro_id', 'year'], how='left')\n",
    "    # Fill missing values with 0 (if no Big 4 office exists in that MSA-year).\n",
    "    df_merge['total_big4_clients'] = df_merge['total_big4_clients'].fillna(0)\n",
    "    \n",
    "    # Compute MARKET_SHARE: OFFICE_SIZE divided by total_big4_clients.\n",
    "    df_merge['MARKET_SHARE'] = df_merge.apply(\n",
    "        lambda row: row['OFFICE_SIZE'] / row['total_big4_clients'] if row['total_big4_clients'] != 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df_merge\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df_office_year = compute_indicators(df_office_year)\n",
    "    print(\"Merged DataFrame with new indicators (full sample):\")\n",
    "    print(df_office_year.head())\n",
    "    \n",
    "    df_office_year_filtered = compute_indicators(df_office_year_filtered)\n",
    "    print(\"Merged DataFrame with new indicators (filtered sample):\")\n",
    "    print(df_office_year_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_office_year.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rename and reorder the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename and reorder the columns\n",
    "def rename_and_reorder_df(df):\n",
    "    df.rename(columns={\n",
    "        'flow_in_rate': 'IN_FLOW_RATE',\n",
    "        'flow_out_rate' : 'OUT_FLOW_RATE',\n",
    "        'net_flow_rate' : 'NET_FLOW_RATE',\n",
    "        'office_city_cleaned' : 'city',\n",
    "        'above_median_salary' : 'HIGH_SALARY',\n",
    "        'office_count_in_MSA' : 'MSA_OFFICES',\n",
    "        'total_auditors' : 'HIRED_AUDITORS_NUM',\n",
    "        'flow_in_rate_employee' : 'IN_FLOW_RATE_EMP',\n",
    "        'flow_out_rate_employee' : 'OUT_FLOW_RATE_EMP',\n",
    "        'net_flow_rate_employee' : 'NET_FLOW_RATE_EMP'\n",
    "        }, inplace=True)\n",
    "\n",
    "    # Define the columns to move to the beginning\n",
    "    cols_to_move = ['office_key_location', \n",
    "                    'office_fullname', \n",
    "                    'year',\n",
    "                    'HIRED_AUDITORS_NUM',\n",
    "                    'IN_FLOW_RATE',\n",
    "                    'OUT_FLOW_RATE',\n",
    "                    'NET_FLOW_RATE',\n",
    "                    'OFFICE_SIZE',\n",
    "                    'LARGE_OFFICE',\n",
    "                    'MARKET_SHARE',\n",
    "                    'HIGH_SALARY',\n",
    "                    'RESTATE_PERC',\n",
    "                    'MSA_OFFICES',\n",
    "                    'OFFICE_GROWTH_NUMBERS',\n",
    "                    'OFFICE_GROWTH_FEES',\n",
    "                    'HIGH_GROWTH',\n",
    "                    'metro_area', \n",
    "                    'city',\n",
    "                    'state'\n",
    "                    ] \n",
    "    # Get the remaining columns (excluding those moved)\n",
    "    remaining_cols = [col for col in df.columns if col not in cols_to_move]\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[cols_to_move + remaining_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_office_year = rename_and_reorder_df(df_office_year)\n",
    "    df_office_year_filtered = rename_and_reorder_df(df_office_year_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(df_office_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build state-level variables\n",
    "* **Data sources：**\n",
    "  * GDP：Bureau of Economic Analysis (BEA)\n",
    "    * https://apps.bea.gov/itable/?ReqID=70&step=1&_gl=1*1acat52*_ga*MTk2NDA1OTAzMi4xNzM5NTI0MzQy*_ga_J4698JNNFT*MTczOTUzMDM1Mi4yLjEuMTczOTUzMDczNy42MC4wLjA.\n",
    "  * Unemployment rate：Bureau of Labor Statistics (BLS)\n",
    "    * https://www.bls.gov/lau/rdscnp16.htm\n",
    "  \n",
    "* **Variables definitions:**\n",
    "  \n",
    "  * $\\text{GDP\\_GROWTH = The average annual percentage change in GDP in the state}$\n",
    "  * $\\text{UNEMPLOYED = The average annual unemployment rate in the state}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Import and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasgui import show\n",
    "\n",
    "# 1. Import data\n",
    "gdp_path = r\"E:\\USA auditor turnover data\\usa state-level gdp and unemployment rate\\State GDP\\1997-2023_USA_STATE_GDP.csv\"\n",
    "unemployment_path = r\"E:\\USA auditor turnover data\\usa state-level gdp and unemployment rate\\state unemployment rate\\1995-2023_USA_ANNUAL_STATE_UNEMPLOYMENT_RATE_RAW.xlsx\"\n",
    "\n",
    "df_gdp = pd.read_csv(gdp_path)\n",
    "df_unemployment = pd.read_excel(unemployment_path)\n",
    "\n",
    "df_gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Build `GDP_GROWTH` variable\n",
    "* Reshape df_gdp to build panel data\n",
    "* Calculate the year-over-year percentage change in GDP for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reshape df_gdp into panel data\n",
    "# 1. Standardize state name and year\n",
    "df_gdp['state'] = df_gdp['state'].str.title()\n",
    "\n",
    "# 2. Use .melt()to turn year row into one column\n",
    "df_gdp_panel = pd.melt(df_gdp, id_vars=['state'], var_name='year', value_name='gdp')\n",
    "df_gdp_panel['year'] = df_gdp_panel['year'].astype(int)\n",
    "\n",
    "# 3. Resort data by state-year\n",
    "df_gdp_panel = df_gdp_panel.sort_values(by=['state', 'year']).reset_index(drop=True)\n",
    "\n",
    "# 4. Generate GDP_GROWTH\n",
    "df_gdp_panel['GDP_GROWTH'] = df_gdp_panel.groupby('state')['gdp'].pct_change() \n",
    "df_gdp_panel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Build `UNEMPLOYED` variable\n",
    "* Sort df_unemployment to build panel data\n",
    "* Notes:\n",
    "  * The original data provide from BLS is exact the average annual unemployment rate for each states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort state unemployment rate data\n",
    "df_unemployment_sorted = df_unemployment.sort_values(by=['state', 'year']).reset_index(drop=True)\n",
    "\n",
    "df_unemployment_sorted['year'] = df_unemployment_sorted['year'].astype(int)\n",
    "\n",
    "# Rename the variable\n",
    "df_unemployment_sorted = df_unemployment_sorted.rename(columns={\n",
    "    'unemployment_rate' : 'UNEMPLOYED'\n",
    "})\n",
    "\n",
    "df_unemployment_sorted = df_unemployment_sorted[df_unemployment_sorted['year'] >= 1997]\n",
    "df_unemployment_sorted = df_unemployment_sorted.sort_values(by=['state', 'year']).reset_index(drop=True)\n",
    "\n",
    "df_unemployment_sorted.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Append GDP and unemployment variables into office-year panel, and reorder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframe(df_left, df_right):\n",
    "    df_left['state'] = df_left['state'].astype(str)\n",
    "    df_right['state'] = df_right['state'].astype(str)\n",
    "\n",
    "    df_left['year'] = df_left['year'].astype(int)\n",
    "    df_right['year'] = df_right['year'].astype(int)\n",
    "\n",
    "    df_merge = df_left.merge(df_right,\n",
    "                                left_on=['state', 'year'], \n",
    "                                right_on =['state', 'year'] ,\n",
    "                                how='outer',\n",
    "                                indicator=True)\n",
    "\n",
    "    merge_report = df_merge['_merge'].value_counts()\n",
    "    print(merge_report) \n",
    "\n",
    "    df_merge = df_merge[df_merge['_merge'] == 'both']\n",
    "    df_merge = df_merge.drop(columns = ['_merge'])\n",
    "    \n",
    "    return df_merge\n",
    "\n",
    "def reorder_dataframe(df):\n",
    "    # Define the columns to move to the beginning\n",
    "    cols_to_move = ['office_key_location', \n",
    "                    'office_fullname', \n",
    "                    'year',\n",
    "                    'HIRED_AUDITORS_NUM',\n",
    "                    'IN_FLOW_RATE',\n",
    "                    'OUT_FLOW_RATE',\n",
    "                    'NET_FLOW_RATE',\n",
    "                    'IN_FLOW_RATE_EMP',\n",
    "                    'OUT_FLOW_RATE_EMP',\n",
    "                    'NET_FLOW_RATE_EMP',                    \n",
    "                    'OFFICE_SIZE',\n",
    "                    'LARGE_OFFICE',\n",
    "                    'MARKET_SHARE',\n",
    "                    'HIGH_SALARY',\n",
    "                    'RESTATE_PERC',\n",
    "                    'MSA_OFFICES',\n",
    "                    'OFFICE_GROWTH_NUMBERS',\n",
    "                    'OFFICE_GROWTH_FEES',\n",
    "                    'HIGH_GROWTH',\n",
    "                    'UNEMPLOYED',\n",
    "                    'GDP_GROWTH',\n",
    "                    'COMBINED_OP_INDICATOR',\n",
    "                    'COMBINED_OP_RATE',\n",
    "                    'gap_indicator_revelio',\n",
    "                    'gap_indicator_aa',\n",
    "                    'copy_2004_indicator',\n",
    "                    'metro_area', \n",
    "                    'city',\n",
    "                    'state'\n",
    "                    ] \n",
    "    # Get the remaining columns (excluding those moved)\n",
    "    remaining_cols = [col for col in df.columns if col not in cols_to_move]\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[cols_to_move + remaining_cols]\n",
    "\n",
    "    return df\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Start to merge office-year\")\n",
    "    df_office_year = merge_dataframe(df_office_year, df_gdp_panel)\n",
    "    df_office_year = merge_dataframe(df_office_year, df_unemployment_sorted)\n",
    "    df_office_year = reorder_dataframe(df_office_year)\n",
    "\n",
    "    print(\"start to merge office-year filtered\")\n",
    "    df_office_year_filtered = merge_dataframe(df_office_year_filtered, df_gdp_panel)  \n",
    "    df_office_year_filtered = merge_dataframe(df_office_year_filtered, df_unemployment_sorted)  \n",
    "    df_office_year_filtered = reorder_dataframe(df_office_year_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Save the office-year panel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_office_year.columns)\n",
    "print(df_office_year_filtered.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Marking Raw Records in the Dataset\n",
    "* rev_raw_office: Set to 1 if an audit office has no discontinued records (i.e., both gap_indicator_revelio and gap_indicator_aa equal 0); otherwise, set to 0.\n",
    "* rev_raw_row: Set to 1 if a row is not inferred (i.e., if gap_indicator_revelio_raw, gap_indicator_aa_row, and copy_2004_indicator are all 0); otherwise, set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create 'rev_raw_office'\n",
    "\n",
    "df_office_year['rev_raw_office'] = 0  # Initialize the column with 0\n",
    "mask = (\n",
    "    (df_office_year['gap_indicator_revelio'] == 0) & \n",
    "    (df_office_year['gap_indicator_aa'] == 0) \n",
    ")\n",
    "df_office_year.loc[mask, 'rev_raw_office'] = 1\n",
    "\n",
    "df_office_year_filtered['rev_raw_office'] = 0  # Initialize the column with 0\n",
    "mask = (\n",
    "    (df_office_year_filtered['gap_indicator_revelio'] == 0) & \n",
    "    (df_office_year_filtered['gap_indicator_aa'] == 0) \n",
    ")\n",
    "df_office_year_filtered.loc[mask, 'rev_raw_office'] = 1\n",
    "\n",
    "# 2. Create 'rev_raw_row'\n",
    "df_office_year['rev_raw_row'] = 0  # Initialize the column with 0\n",
    "mask = (\n",
    "    (df_office_year['gap_indicator_revelio_row'] == 0) & \n",
    "    (df_office_year['gap_indicator_aa_row'] == 0) &\n",
    "    (df_office_year['copy_2004_indicator'] == 0) \n",
    ")\n",
    "df_office_year.loc[mask, 'rev_raw_row'] = 1\n",
    "\n",
    "df_office_year_filtered['rev_raw_row'] = 0  # Initialize the column with 0\n",
    "mask = (\n",
    "    (df_office_year_filtered['gap_indicator_revelio_row'] == 0) & \n",
    "    (df_office_year_filtered['gap_indicator_aa_row'] == 0) &\n",
    "    (df_office_year_filtered['copy_2004_indicator'] == 0) \n",
    ")\n",
    "df_office_year_filtered.loc[mask, 'rev_raw_row'] = 1\n",
    "\n",
    "# 3. Reorder the columns\n",
    "# 3.1 Define the reorder function\n",
    "def reorder_dataframe(df):\n",
    "    # Define the columns to move to the beginning\n",
    "    cols_to_move = ['office_key_location', \n",
    "                    'office_fullname', \n",
    "                    'year',\n",
    "                    'HIRED_AUDITORS_NUM',\n",
    "                    'IN_FLOW_RATE',\n",
    "                    'OUT_FLOW_RATE',\n",
    "                    'NET_FLOW_RATE',\n",
    "                    'IN_FLOW_RATE_EMP',\n",
    "                    'OUT_FLOW_RATE_EMP',\n",
    "                    'NET_FLOW_RATE_EMP',                    \n",
    "                    'OFFICE_SIZE',\n",
    "                    'LARGE_OFFICE',\n",
    "                    'MARKET_SHARE',\n",
    "                    'HIGH_SALARY',\n",
    "                    'RESTATE_PERC',\n",
    "                    'MSA_OFFICES',\n",
    "                    'OFFICE_GROWTH_NUMBERS',\n",
    "                    'OFFICE_GROWTH_FEES',\n",
    "                    'HIGH_GROWTH',\n",
    "                    'UNEMPLOYED',\n",
    "                    'GDP_GROWTH',\n",
    "                    'COMBINED_OP_INDICATOR',\n",
    "                    'COMBINED_OP_RATE',\n",
    "                    'rev_raw_office',\n",
    "                    'rev_raw_row',\n",
    "                    'gap_indicator_revelio',\n",
    "                    'gap_indicator_revelio_row',\n",
    "                    'gap_indicator_aa',\n",
    "                    'gap_indicator_aa_row',\n",
    "                    'copy_2004_indicator',\n",
    "                    'metro_area', \n",
    "                    'city',\n",
    "                    'state'\n",
    "                    ] \n",
    "    # Get the remaining columns (excluding those moved)\n",
    "    remaining_cols = [col for col in df.columns if col not in cols_to_move]\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[cols_to_move + remaining_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "# 3.2 Apply the reorder function\n",
    "df_office_year = reorder_dataframe(df_office_year)\n",
    "df_office_year_filtered = reorder_dataframe(df_office_year_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(df_office_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Save the office-year panel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path1 = r\"E:\\USA auditor turnover data\\result data\\office-year panel date_final.csv\"\n",
    "save_path2 = r\"E:\\USA auditor turnover data\\result data\\office-year panel date_filtered_final.csv\"\n",
    "\n",
    "df_office_year = df_office_year.sort_values(by=['office_key_location', 'year'])\n",
    "df_office_year_filtered = df_office_year_filtered.sort_values(by=['office_key_location', 'year'])\n",
    "\n",
    "df_office_year.to_csv(save_path1, index=False)\n",
    "df_office_year_filtered.to_csv(save_path2, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
