{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Revelio labs and Audit Analytics data, and built rest of variables\n",
    "* Jie XIA, SUSTech\n",
    "* 2025-02-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dataset\n",
    "* Panel dataset built from revelio labs\n",
    "  * `revelio` is sample include auditors who have ever worked in multiple offices or places\n",
    "  * `revelio_filtered` is sample exclude auditors who have ever worked in multiple offices or places\n",
    "* Panel dataset Built from Audit Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load in csv file\n",
      "Files loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "revelio_path = r\"E:\\USA auditor turnover data\\turnover data\\office-year_auditor_turnover_us.csv\"\n",
    "revelio_filtered_path = r\"E:\\USA auditor turnover data\\turnover data\\office-year_auditor_turnover_us_filtered.csv\"\n",
    "aa_path = r\"e:\\USA auditor turnover data\\Audit Analytics data\\office-year us auditor variables from AA data.csv\"\n",
    "\n",
    "print(\"Start to load in csv file\")\n",
    "df_revelio = pd.read_csv(revelio_path, engine='pyarrow')\n",
    "df_revelio_filtered = pd.read_csv(revelio_filtered_path, engine='pyarrow')\n",
    "df_aa = pd.read_csv(aa_path, engine='pyarrow')\n",
    "print(\"Files loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_revelio.columns)\n",
    "#print(df_aa.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_revelio.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_aa.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merge Revelio and AA variables\n",
    "* Merge dataset based on `office_key_location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6904 office in revelio\n",
      "There are 5420 office in revelio_filtered\n",
      "There are 1348 office in aa\n"
     ]
    }
   ],
   "source": [
    "df_revelio['office_key_location'] = df_revelio['office_key_location'].astype(str)\n",
    "df_revelio_filtered['office_key_location'] = df_revelio_filtered['office_key_location'].astype(str)\n",
    "df_revelio['year'] = df_revelio['year'].astype(int)\n",
    "df_revelio_filtered['year'] = df_revelio_filtered['year'].astype(int)\n",
    "\n",
    "df_aa['office_key_location'] = df_aa['office_key_location'].astype(str)\n",
    "df_aa['FY_IC_OP'] = df_aa['FY_IC_OP'].astype(int)\n",
    "\n",
    "print(f\"There are {df_revelio['office_key_location'].nunique()} office in revelio\")\n",
    "print(f\"There are {df_revelio_filtered['office_key_location'].nunique()} office in revelio_filtered\")\n",
    "print(f\"There are {df_aa['office_key_location'].nunique()} office in aa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For variables in aa data, create offices's value from 2001 to 2003 base on offices' values in 2004, if they do not exist.\n",
    "* And create a indicator column `copy_2004_indicator` to indicate these offices sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 458 office samples in 2004\n",
      "Number of rows in the extended df_aa: 12676\n",
      "   office_key_location  FY_IC_OP  OFFICE_SIZE  TOTAL_RESTATEMENT  \\\n",
      "0  1, Albany, New York      2001          5.0                0.0   \n",
      "1  1, Albany, New York      2002          5.0                0.0   \n",
      "2  1, Albany, New York      2003          5.0                0.0   \n",
      "3  1, Albany, New York      2004          5.0                0.0   \n",
      "4  1, Albany, New York      2005          6.0                0.0   \n",
      "5  1, Albany, New York      2006          7.0                0.0   \n",
      "6  1, Albany, New York      2007          3.0                0.0   \n",
      "7  1, Albany, New York      2008          3.0                0.0   \n",
      "8  1, Albany, New York      2009          3.0                0.0   \n",
      "9  1, Albany, New York      2010          4.0                0.0   \n",
      "\n",
      "   TOTAL_AUDIT_FEE  TOTAL_COMBINED_IC  TOTAL_REPORTS  COMBINED_OP_INDICATOR  \\\n",
      "0        4920460.0                4.0            5.0                    1.0   \n",
      "1        4920460.0                4.0            5.0                    1.0   \n",
      "2        4920460.0                4.0            5.0                    1.0   \n",
      "3        4920460.0                4.0            5.0                    1.0   \n",
      "4        7946760.0                6.0            6.0                    1.0   \n",
      "5        9348819.0                7.0            7.0                    1.0   \n",
      "6        5386323.0                3.0            3.0                    1.0   \n",
      "7        5746700.0                2.0            3.0                    1.0   \n",
      "8        4925580.0                3.0            3.0                    1.0   \n",
      "9        6933150.0                4.0            4.0                    1.0   \n",
      "\n",
      "   COMBINED_OP_RATE  gap_indicator_aa_row  gap_indicator_aa  \\\n",
      "0          0.800000                     0                 0   \n",
      "1          0.800000                     0                 0   \n",
      "2          0.800000                     0                 0   \n",
      "3          0.800000                     0                 0   \n",
      "4          1.000000                     0                 0   \n",
      "5          1.000000                     0                 0   \n",
      "6          1.000000                     0                 0   \n",
      "7          0.666667                     0                 0   \n",
      "8          1.000000                     0                 0   \n",
      "9          1.000000                     0                 0   \n",
      "\n",
      "   OFFICE_GROWTH_NUMBERS  OFFICE_GROWTH_FEES  RESTATE_PERC  HIGH_GROWTH  \\\n",
      "0                    NaN                 NaN           0.0            0   \n",
      "1                    NaN                 NaN           0.0            0   \n",
      "2                    NaN                 NaN           0.0            0   \n",
      "3                    NaN                 NaN           0.0            0   \n",
      "4               0.200000            0.615044           0.0            1   \n",
      "5               0.166667            0.176432           0.0            1   \n",
      "6              -0.571429           -0.423850           0.0            0   \n",
      "7               0.000000            0.066906           0.0            1   \n",
      "8               0.000000           -0.142885           0.0            0   \n",
      "9               0.333333            0.407580           0.0            1   \n",
      "\n",
      "   BIG4_flag  copy_2004_indicator  \n",
      "0          1                    1  \n",
      "1          1                    1  \n",
      "2          1                    1  \n",
      "3          1                    0  \n",
      "4          1                    0  \n",
      "5          1                    0  \n",
      "6          1                    0  \n",
      "7          1                    0  \n",
      "8          1                    0  \n",
      "9          1                    0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Add a 'copy_value' column to mark original records as 0.\n",
    "df_aa['copy_2004_indicator'] = 0\n",
    "\n",
    "# Define the target years that need to be filled in (the years that are missing).\n",
    "target_years = [2001, 2002, 2003]\n",
    "\n",
    "# Extract the data for 2004 and, for each office, take the first record \n",
    "df_aa_2004 = df_aa[df_aa['FY_IC_OP'] == 2004].drop_duplicates(subset='office_key_location')\n",
    "\n",
    "# List to store rows that need to be added for the missing years.\n",
    "rows_to_add = []\n",
    "\n",
    "# For each office from 2004:\n",
    "for _, row in df_aa_2004.iterrows():\n",
    "    office = row['office_key_location']\n",
    "    # Identify the years (from 2001 to 2003) that already have records for this office.\n",
    "    existing_years = df_aa.loc[\n",
    "        (df_aa['office_key_location'] == office) & (df_aa['FY_IC_OP'].isin(target_years)),\n",
    "        'FY_IC_OP'\n",
    "    ].unique().tolist()\n",
    "    # Determine the missing years.\n",
    "    missing_years = set(target_years) - set(existing_years)\n",
    "    \n",
    "    # For each missing year, duplicate the 2004 record, update the year, and set copy_value to 1.\n",
    "    for yr in missing_years:\n",
    "        new_row = row.copy()\n",
    "        new_row['FY_IC_OP'] = yr\n",
    "        new_row['copy_2004_indicator'] = 1\n",
    "        rows_to_add.append(new_row)\n",
    "\n",
    "# If there are rows to add, convert them to a DataFrame and concatenate with the original df_aa.\n",
    "if rows_to_add:\n",
    "    df_add = pd.DataFrame(rows_to_add)\n",
    "    df_aa_extended = pd.concat([df_aa, df_add], ignore_index=True)\n",
    "else:\n",
    "    df_aa_extended = df_aa.copy()\n",
    "\n",
    "# Sort the extended DataFrame by office_key_location and FY_IC_OP, then reset the index.\n",
    "df_aa_extended = df_aa_extended.sort_values(by=['office_key_location', 'FY_IC_OP']).reset_index(drop=True)\n",
    "\n",
    "# Output statistics.\n",
    "num_offices_2004 = df_aa[df_aa['FY_IC_OP'] == 2004]['office_key_location'].nunique()\n",
    "print(f\"There are {num_offices_2004} office samples in 2004\")\n",
    "print(\"Number of rows in the extended df_aa:\", df_aa_extended.shape[0])\n",
    "\n",
    "# Display a sample of the extended data.\n",
    "print(df_aa_extended.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merge the revelio and aa data based on `office_key_location` and `year`(`FY_IC_OP`)\n",
    "* Print the description of merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to merge Revelio with AA data\n",
      "Revelio row counts for years from 1990 onwards:\n",
      "    year  revelio_count\n",
      "0   1990           1217\n",
      "1   1991           1232\n",
      "2   1992           1257\n",
      "3   1993           1296\n",
      "4   1994           1325\n",
      "5   1995           1359\n",
      "6   1996           1381\n",
      "7   1997           1470\n",
      "8   1998           1562\n",
      "9   1999           1602\n",
      "10  2000           1630\n",
      "11  2001           1624\n",
      "12  2002           1610\n",
      "13  2003           1639\n",
      "14  2004           1728\n",
      "15  2005           1820\n",
      "16  2006           1891\n",
      "17  2007           1968\n",
      "18  2008           1964\n",
      "19  2009           1896\n",
      "20  2010           1803\n",
      "21  2011           1704\n",
      "22  2012           1658\n",
      "23  2013           1652\n",
      "24  2014           1628\n",
      "25  2015           1640\n",
      "26  2016           1670\n",
      "27  2017           1685\n",
      "28  2018           1735\n",
      "29  2019           1767\n",
      "30  2020           1836\n",
      "31  2021           1917\n",
      "32  2022           2109\n",
      "33  2023           1951\n",
      "34  2024           1723\n",
      "AA row counts per year:\n",
      "    FY_IC_OP  aa_count\n",
      "0       2001       458\n",
      "1       2002       458\n",
      "2       2003       458\n",
      "3       2004       458\n",
      "4       2005       549\n",
      "5       2006       597\n",
      "6       2007       615\n",
      "7       2008       618\n",
      "8       2009       602\n",
      "9       2010       587\n",
      "10      2011       576\n",
      "11      2012       558\n",
      "12      2013       558\n",
      "13      2014       564\n",
      "14      2015       561\n",
      "15      2016       563\n",
      "16      2017       571\n",
      "17      2018       569\n",
      "18      2019       566\n",
      "19      2020       503\n",
      "20      2021       503\n",
      "21      2022       492\n",
      "22      2023       473\n",
      "23      2024       219\n",
      "Overall merge status:\n",
      "_merge\n",
      "left_only     62145\n",
      "both           6521\n",
      "right_only     6155\n",
      "Name: count, dtype: int64\n",
      "Merged (both) record counts per year:\n",
      "      year  both_count\n",
      "0   2001.0         191\n",
      "1   2002.0         194\n",
      "2   2003.0         196\n",
      "3   2004.0         201\n",
      "4   2005.0         230\n",
      "5   2006.0         247\n",
      "6   2007.0         252\n",
      "7   2008.0         255\n",
      "8   2009.0         256\n",
      "9   2010.0         280\n",
      "10  2011.0         285\n",
      "11  2012.0         289\n",
      "12  2013.0         291\n",
      "13  2014.0         294\n",
      "14  2015.0         323\n",
      "15  2016.0         331\n",
      "16  2017.0         341\n",
      "17  2018.0         348\n",
      "18  2019.0         356\n",
      "19  2020.0         322\n",
      "20  2021.0         320\n",
      "21  2022.0         309\n",
      "22  2023.0         291\n",
      "23  2024.0         119\n",
      "Start to merge filtered Revelio with AA data\n",
      "Revelio row counts for years from 1990 onwards:\n",
      "    year  revelio_count\n",
      "0   1990           1008\n",
      "1   1991           1024\n",
      "2   1992           1033\n",
      "3   1993           1065\n",
      "4   1994           1075\n",
      "5   1995           1096\n",
      "6   1996           1137\n",
      "7   1997           1184\n",
      "8   1998           1248\n",
      "9   1999           1287\n",
      "10  2000           1294\n",
      "11  2001           1285\n",
      "12  2002           1273\n",
      "13  2003           1287\n",
      "14  2004           1347\n",
      "15  2005           1436\n",
      "16  2006           1492\n",
      "17  2007           1545\n",
      "18  2008           1539\n",
      "19  2009           1465\n",
      "20  2010           1372\n",
      "21  2011           1299\n",
      "22  2012           1241\n",
      "23  2013           1215\n",
      "24  2014           1212\n",
      "25  2015           1218\n",
      "26  2016           1224\n",
      "27  2017           1253\n",
      "28  2018           1272\n",
      "29  2019           1258\n",
      "30  2020           1276\n",
      "31  2021           1302\n",
      "32  2022           1379\n",
      "33  2023           1344\n",
      "34  2024           1243\n",
      "AA row counts per year:\n",
      "    FY_IC_OP  aa_count\n",
      "0       2001       458\n",
      "1       2002       458\n",
      "2       2003       458\n",
      "3       2004       458\n",
      "4       2005       549\n",
      "5       2006       597\n",
      "6       2007       615\n",
      "7       2008       618\n",
      "8       2009       602\n",
      "9       2010       587\n",
      "10      2011       576\n",
      "11      2012       558\n",
      "12      2013       558\n",
      "13      2014       564\n",
      "14      2015       561\n",
      "15      2016       563\n",
      "16      2017       571\n",
      "17      2018       569\n",
      "18      2019       566\n",
      "19      2020       503\n",
      "20      2021       503\n",
      "21      2022       492\n",
      "22      2023       473\n",
      "23      2024       219\n",
      "Overall merge status:\n",
      "_merge\n",
      "left_only     48011\n",
      "right_only     7075\n",
      "both           5601\n",
      "Name: count, dtype: int64\n",
      "Merged (both) record counts per year:\n",
      "      year  both_count\n",
      "0   2001.0         177\n",
      "1   2002.0         179\n",
      "2   2003.0         180\n",
      "3   2004.0         186\n",
      "4   2005.0         213\n",
      "5   2006.0         228\n",
      "6   2007.0         231\n",
      "7   2008.0         234\n",
      "8   2009.0         234\n",
      "9   2010.0         237\n",
      "10  2011.0         238\n",
      "11  2012.0         236\n",
      "12  2013.0         240\n",
      "13  2014.0         244\n",
      "14  2015.0         268\n",
      "15  2016.0         278\n",
      "16  2017.0         287\n",
      "17  2018.0         292\n",
      "18  2019.0         296\n",
      "19  2020.0         267\n",
      "20  2021.0         261\n",
      "21  2022.0         252\n",
      "22  2023.0         239\n",
      "23  2024.0         104\n"
     ]
    }
   ],
   "source": [
    "from pandasgui import show\n",
    "\n",
    "def merge_dataframe(df_revelio, df_aa):\n",
    "    # 1. Filter Revelio data to include only records from 1990 onwards and count rows per year.\n",
    "    revelio_filtered_year = df_revelio[df_revelio['year'] >= 1990]\n",
    "    revelio_year_counts = revelio_filtered_year.groupby('year').size().reset_index(name='revelio_count')\n",
    "    print(\"Revelio row counts for years from 1990 onwards:\")\n",
    "    print(revelio_year_counts)\n",
    "    \n",
    "    # 2. Count the number of records per year in the AA data.\n",
    "    aa_year_counts = df_aa.groupby('FY_IC_OP').size().reset_index(name='aa_count')\n",
    "    print(\"AA row counts per year:\")\n",
    "    print(aa_year_counts)\n",
    "    \n",
    "    # 3. Merge the original Revelio data with AA data using office_key_location and year.\n",
    "    #    The merge is done as an outer join to allow inspection of merge results.\n",
    "    df_merge = df_revelio.merge(\n",
    "        df_aa,\n",
    "        left_on=['office_key_location', 'year'], \n",
    "        right_on=['office_key_location', 'FY_IC_OP'],\n",
    "        how='outer',\n",
    "        indicator=True\n",
    "    )\n",
    "\n",
    "    # Print overall merge status using the _merge column.\n",
    "    merge_report = df_merge['_merge'].value_counts()\n",
    "    print(\"Overall merge status:\")\n",
    "    print(merge_report)\n",
    "\n",
    "    # Count the number of merged records (i.e., records present in both datasets) for each year.\n",
    "    yearly_both = (\n",
    "        df_merge[df_merge['_merge'] == 'both']\n",
    "        .groupby('year')\n",
    "        .size()\n",
    "        .reset_index(name='both_count')\n",
    "    )\n",
    "    print(\"Merged (both) record counts per year:\")\n",
    "    print(yearly_both)\n",
    "    \n",
    "    # Optionally, keep only the records that successfully merged from both datasets.\n",
    "    df_merge = df_merge[df_merge['_merge'] == 'both']\n",
    "    # Drop the merge indicator and redundant FY_IC_OP column.\n",
    "    df_merge = df_merge.drop(columns=['_merge', 'FY_IC_OP'])\n",
    "\n",
    "    return df_merge\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Start to merge Revelio with AA data\")\n",
    "    df_office_year = merge_dataframe(df_revelio, df_aa_extended)\n",
    "    df_office_year.to_csv(r\"E:\\USA auditor turnover data\\result data\\revelio_aa_merge.csv\", index=False)\n",
    "    \n",
    "    print(\"Start to merge filtered Revelio with AA data\")\n",
    "    df_office_year_filtered = merge_dataframe(df_revelio_filtered, df_aa_extended)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reset the gap_indicator_revelio_office\n",
    "  * Because when generate gap_indicator_revelio_office, we use the whole year range. However, now the year range is deceased to 2001. Therefore, we need to reset the gap of office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Reset indicators to 0\n",
    "df_office_year['gap_indicator_revelio'] = 0\n",
    "df_office_year_filtered['gap_indicator_revelio'] = 0\n",
    "df_office_year['gap_indicator_aa'] = 0\n",
    "df_office_year_filtered['gap_indicator_aa'] = 0\n",
    "\n",
    "# Step 2: Recalculate based on row indicators\n",
    "\n",
    "df_office_year.loc[df_office_year.groupby('office_id')['gap_indicator_revelio_row'].transform(lambda x: (x == 1).any()), 'gap_indicator_revelio'] = 1\n",
    "df_office_year_filtered.loc[df_office_year_filtered.groupby('office_id')['gap_indicator_revelio_row'].transform(lambda x: (x == 1).any()), 'gap_indicator_revelio'] = 1\n",
    "\n",
    "df_office_year.loc[df_office_year.groupby('office_id')['gap_indicator_aa_row'].transform(lambda x: (x == 1).any()), 'gap_indicator_aa'] = 1\n",
    "df_office_year_filtered.loc[df_office_year_filtered.groupby('office_id')['gap_indicator_aa_row'].transform(lambda x: (x == 1).any()), 'gap_indicator_aa'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Manually check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_office_year_check = df_office_year.sort_values(by=['office_id', 'year'])\n",
    "\n",
    "path = r\"E:\\USA auditor turnover data\\result data\\office_year_panel_for_check_gap_reset.csv\"\n",
    "\n",
    "df_office_year_check.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrect `gap_indicator_revelio`: 0\n",
      "Number of incorrect `gap_indicator_aa`: 0\n",
      "Incorrect `gap_indicator_revelio` examples:\n",
      "Empty DataFrame\n",
      "Columns: [office_id, year, gap_indicator_revelio_row, gap_indicator_revelio]\n",
      "Index: []\n",
      "Incorrect `gap_indicator_aa` examples:\n",
      "Empty DataFrame\n",
      "Columns: [office_id, year, gap_indicator_aa_row, gap_indicator_aa]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for incorrect `gap_indicator_revelio`\n",
    "incorrect_revelio = df_office_year.groupby('office_id').filter(\n",
    "    lambda g: (g['gap_indicator_revelio_row'] == 0).all() and (g['gap_indicator_revelio'].iloc[0] == 1)\n",
    ")\n",
    "\n",
    "# Check for incorrect `gap_indicator_aa`\n",
    "incorrect_aa = df_office_year.groupby('office_id').filter(\n",
    "    lambda g: (g['gap_indicator_aa_row'] == 0).all() and (g['gap_indicator_aa'].iloc[0] == 1)\n",
    ")\n",
    "\n",
    "# Print the number of incorrect cases\n",
    "print(f\"Number of incorrect `gap_indicator_revelio`: {len(incorrect_revelio['office_id'].unique())}\")\n",
    "print(f\"Number of incorrect `gap_indicator_aa`: {len(incorrect_aa['office_id'].unique())}\")\n",
    "\n",
    "# Show a few examples for debugging\n",
    "print(\"Incorrect `gap_indicator_revelio` examples:\")\n",
    "print(incorrect_revelio[['office_id', 'year', 'gap_indicator_revelio_row', 'gap_indicator_revelio']].drop_duplicates().head(10))\n",
    "\n",
    "print(\"Incorrect `gap_indicator_aa` examples:\")\n",
    "print(incorrect_aa[['office_id', 'year', 'gap_indicator_aa_row', 'gap_indicator_aa']].drop_duplicates().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Build office-level variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute LARGE_OFFICE Indicator:\n",
    "\n",
    "   * Calculate the median office size (using OFFICE_SIZE) for each metro_id and year.\n",
    "   * Create a new indicator, LARGE_OFFICE, which is set to 1 if an office's OFFICE_SIZE is greater than the computed median, and 0 otherwise.\n",
    "2. Compute MARKET_SHARE Indicator:\n",
    "\n",
    "   * For each metro_id and year, sum the OFFICE_SIZE of all offices flagged as Big 4 (BIG4_flag==1) to determine the total number of Big 4 clients (total_big4_clients).\n",
    "   * Merge this total back into the main DataFrame, filling missing values with 0.\n",
    "   * Compute MARKET_SHARE as the ratio of an office's OFFICE_SIZE to total_big4_clients, defaulting to 0 if no Big 4 clients are present.\n",
    "3. Return the Updated DataFrame:\n",
    "\n",
    "   * The function returns the DataFrame with the newly computed indicators, which are then applied to both full and filtered samples, and the first few rows are printed for verification.\n",
    "\n",
    "\n",
    "* **Variables definitions:**\n",
    "  * $\\text{LARGE\\_OFFICE} = \\text{if an audit office’s size is greater than the sample median in an MSA}$\n",
    "  * $\\text{MARKET\\_SHARE} = \\cfrac{\\text{Total number of audit clients in an office in a year}}{\\text{Total number of audit clients for all Big 4 offices in the same MSA in a year}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame with new indicators (full sample):\n",
      "     year  office_id                              office_fullname  \\\n",
      "0  2001.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "1  2002.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "2  2003.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "3  2004.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "4  2005.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "\n",
      "   office_key_location  metro_id                metro_area  total_auditors  \\\n",
      "0  1, Albany, New York      76.0  Albany Metropolitan Area             3.0   \n",
      "1  1, Albany, New York      76.0  Albany Metropolitan Area             1.0   \n",
      "2  1, Albany, New York      76.0  Albany Metropolitan Area             1.0   \n",
      "3  1, Albany, New York      76.0  Albany Metropolitan Area             1.0   \n",
      "4  1, Albany, New York      76.0  Albany Metropolitan Area             1.0   \n",
      "\n",
      "   flow_in  flow_out  net_flow  ...  OFFICE_GROWTH_NUMBERS  \\\n",
      "0      2.0       1.0       1.0  ...                    NaN   \n",
      "1      0.0       2.0      -2.0  ...                    NaN   \n",
      "2      0.0       0.0       0.0  ...                    NaN   \n",
      "3      1.0       1.0       0.0  ...                    NaN   \n",
      "4      0.0       0.0       0.0  ...                    0.2   \n",
      "\n",
      "   OFFICE_GROWTH_FEES  RESTATE_PERC  HIGH_GROWTH  BIG4_flag  \\\n",
      "0                 NaN           0.0          0.0        1.0   \n",
      "1                 NaN           0.0          0.0        1.0   \n",
      "2                 NaN           0.0          0.0        1.0   \n",
      "3                 NaN           0.0          0.0        1.0   \n",
      "4            0.615044           0.0          1.0        1.0   \n",
      "\n",
      "   copy_2004_indicator  median_office_size  LARGE_OFFICE  total_big4_clients  \\\n",
      "0                  1.0                 6.5             0                13.0   \n",
      "1                  1.0                 6.5             0                13.0   \n",
      "2                  1.0                 6.5             0                13.0   \n",
      "3                  0.0                 6.5             0                13.0   \n",
      "4                  0.0                 9.0             0                18.0   \n",
      "\n",
      "  MARKET_SHARE  \n",
      "0     0.384615  \n",
      "1     0.384615  \n",
      "2     0.384615  \n",
      "3     0.384615  \n",
      "4     0.333333  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "Merged DataFrame with new indicators (filtered sample):\n",
      "     year  office_id                              office_fullname  \\\n",
      "0  2001.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "1  2002.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "2  2003.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "3  2004.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "4  2005.0      416.0  Pricewaterhousecoopers Llp Albany, New York   \n",
      "\n",
      "   office_key_location  metro_id                metro_area  total_auditors  \\\n",
      "0  1, Albany, New York      76.0  Albany Metropolitan Area             3.0   \n",
      "1  1, Albany, New York      76.0  Albany Metropolitan Area             1.0   \n",
      "2  1, Albany, New York      76.0  Albany Metropolitan Area             1.0   \n",
      "3  1, Albany, New York      76.0  Albany Metropolitan Area             1.0   \n",
      "4  1, Albany, New York      76.0  Albany Metropolitan Area             1.0   \n",
      "\n",
      "   flow_in  flow_out  net_flow  ...  OFFICE_GROWTH_NUMBERS  \\\n",
      "0      2.0       1.0       1.0  ...                    NaN   \n",
      "1      0.0       2.0      -2.0  ...                    NaN   \n",
      "2      0.0       0.0       0.0  ...                    NaN   \n",
      "3      1.0       1.0       0.0  ...                    NaN   \n",
      "4      0.0       0.0       0.0  ...                    0.2   \n",
      "\n",
      "   OFFICE_GROWTH_FEES  RESTATE_PERC  HIGH_GROWTH  BIG4_flag  \\\n",
      "0                 NaN           0.0          0.0        1.0   \n",
      "1                 NaN           0.0          0.0        1.0   \n",
      "2                 NaN           0.0          0.0        1.0   \n",
      "3                 NaN           0.0          0.0        1.0   \n",
      "4            0.615044           0.0          1.0        1.0   \n",
      "\n",
      "   copy_2004_indicator  median_office_size  LARGE_OFFICE  total_big4_clients  \\\n",
      "0                  1.0                 6.5             0                13.0   \n",
      "1                  1.0                 6.5             0                13.0   \n",
      "2                  1.0                 6.5             0                13.0   \n",
      "3                  0.0                 6.5             0                13.0   \n",
      "4                  0.0                 9.0             0                18.0   \n",
      "\n",
      "  MARKET_SHARE  \n",
      "0     0.384615  \n",
      "1     0.384615  \n",
      "2     0.384615  \n",
      "3     0.384615  \n",
      "4     0.333333  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "def compute_indicators(df_merge):\n",
    "    \"\"\"\n",
    "    Computes two new indicators:\n",
    "      1. LARGE_OFFICE: 1 if an office's size (OFFICE_SIZE) is greater than the median \n",
    "         office size for its MSA (identified by metro_id) in that year.\n",
    "      2. MARKET_SHARE: OFFICE_SIZE divided by the total OFFICE_SIZE of all Big 4 offices \n",
    "         (BIG4_flag==1) in the same MSA and year.\n",
    "    \"\"\"\n",
    "    # ---------------------------\n",
    "    # LARGE_OFFICE Calculation\n",
    "    # ---------------------------\n",
    "    # Compute the median office size (using OFFICE_SIZE) for each metro_id and year.\n",
    "    df_merge['median_office_size'] = df_merge.groupby(['metro_id', 'year'])['OFFICE_SIZE'].transform('median')\n",
    "    # Set LARGE_OFFICE = 1 if OFFICE_SIZE > median_office_size, else 0.\n",
    "    df_merge['LARGE_OFFICE'] = (df_merge['OFFICE_SIZE'] > df_merge['median_office_size']).astype(int)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # MARKET_SHARE Calculation\n",
    "    # ---------------------------\n",
    "    # First, for each metro_id and year, compute total OFFICE_SIZE for all Big 4 offices.\n",
    "    # We filter rows with BIG4_flag==1 and group by metro_id and year.\n",
    "    big4_totals = (\n",
    "        df_merge[df_merge['BIG4_flag'] == 1]\n",
    "        .groupby(['metro_id', 'year'])['OFFICE_SIZE']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={'OFFICE_SIZE': 'total_big4_clients'})\n",
    "    )\n",
    "    \n",
    "    # Merge the total Big 4 clients info back into df_merge.\n",
    "    df_merge = df_merge.merge(big4_totals, on=['metro_id', 'year'], how='left')\n",
    "    # Fill missing values with 0 (if no Big 4 office exists in that MSA-year).\n",
    "    df_merge['total_big4_clients'] = df_merge['total_big4_clients'].fillna(0)\n",
    "    \n",
    "    # Compute MARKET_SHARE: OFFICE_SIZE divided by total_big4_clients.\n",
    "    df_merge['MARKET_SHARE'] = df_merge.apply(\n",
    "        lambda row: row['OFFICE_SIZE'] / row['total_big4_clients'] if row['total_big4_clients'] != 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df_merge\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df_office_year = compute_indicators(df_office_year)\n",
    "    print(\"Merged DataFrame with new indicators (full sample):\")\n",
    "    print(df_office_year.head())\n",
    "    \n",
    "    df_office_year_filtered = compute_indicators(df_office_year_filtered)\n",
    "    print(\"Merged DataFrame with new indicators (filtered sample):\")\n",
    "    print(df_office_year_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'office_id', 'office_fullname', 'office_key_location',\n",
      "       'metro_id', 'metro_area', 'total_auditors', 'flow_in', 'flow_out',\n",
      "       'net_flow', 'flow_in_rate', 'flow_out_rate', 'net_flow_rate',\n",
      "       'gap_indicator_revelio_row', 'total_employees', 'flow_in_rate_employee',\n",
      "       'flow_out_rate_employee', 'net_flow_rate_employee',\n",
      "       'gap_indicator_revelio', 'state', 'office_city_cleaned',\n",
      "       'office_avg_salary', 'metro_median_salary', 'above_median_salary',\n",
      "       'office_count_in_MSA', 'OFFICE_SIZE', 'TOTAL_RESTATEMENT',\n",
      "       'TOTAL_AUDIT_FEE', 'TOTAL_COMBINED_IC', 'TOTAL_REPORTS',\n",
      "       'COMBINED_OP_INDICATOR', 'COMBINED_OP_RATE', 'gap_indicator_aa_row',\n",
      "       'gap_indicator_aa', 'OFFICE_GROWTH_NUMBERS', 'OFFICE_GROWTH_FEES',\n",
      "       'RESTATE_PERC', 'HIGH_GROWTH', 'BIG4_flag', 'copy_2004_indicator',\n",
      "       'median_office_size', 'LARGE_OFFICE', 'total_big4_clients',\n",
      "       'MARKET_SHARE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_office_year.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rename and reorder the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename and reorder the columns\n",
    "def rename_and_reorder_df(df):\n",
    "    df.rename(columns={\n",
    "        'flow_in_rate': 'IN_FLOW_RATE',\n",
    "        'flow_out_rate' : 'OUT_FLOW_RATE',\n",
    "        'net_flow_rate' : 'NET_FLOW_RATE',\n",
    "        'office_city_cleaned' : 'city',\n",
    "        'above_median_salary' : 'HIGH_SALARY',\n",
    "        'office_count_in_MSA' : 'MSA_OFFICES',\n",
    "        'total_auditors' : 'HIRED_AUDITORS_NUM',\n",
    "        'flow_in_rate_employee' : 'IN_FLOW_RATE_EMP',\n",
    "        'flow_out_rate_employee' : 'OUT_FLOW_RATE_EMP',\n",
    "        'net_flow_rate_employee' : 'NET_FLOW_RATE_EMP'\n",
    "        }, inplace=True)\n",
    "\n",
    "    # Define the columns to move to the beginning\n",
    "    cols_to_move = ['office_key_location', \n",
    "                    'office_fullname', \n",
    "                    'year',\n",
    "                    'HIRED_AUDITORS_NUM',\n",
    "                    'IN_FLOW_RATE',\n",
    "                    'OUT_FLOW_RATE',\n",
    "                    'NET_FLOW_RATE',\n",
    "                    'OFFICE_SIZE',\n",
    "                    'LARGE_OFFICE',\n",
    "                    'MARKET_SHARE',\n",
    "                    'HIGH_SALARY',\n",
    "                    'RESTATE_PERC',\n",
    "                    'MSA_OFFICES',\n",
    "                    'OFFICE_GROWTH_NUMBERS',\n",
    "                    'OFFICE_GROWTH_FEES',\n",
    "                    'HIGH_GROWTH',\n",
    "                    'metro_area', \n",
    "                    'city',\n",
    "                    'state'\n",
    "                    ] \n",
    "    # Get the remaining columns (excluding those moved)\n",
    "    remaining_cols = [col for col in df.columns if col not in cols_to_move]\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[cols_to_move + remaining_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_office_year = rename_and_reorder_df(df_office_year)\n",
    "    df_office_year_filtered = rename_and_reorder_df(df_office_year_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(df_office_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build state-level variables\n",
    "* **Data sources：**\n",
    "  * GDP：Bureau of Economic Analysis (BEA)\n",
    "    * https://apps.bea.gov/itable/?ReqID=70&step=1&_gl=1*1acat52*_ga*MTk2NDA1OTAzMi4xNzM5NTI0MzQy*_ga_J4698JNNFT*MTczOTUzMDM1Mi4yLjEuMTczOTUzMDczNy42MC4wLjA.\n",
    "  * Unemployment rate：Bureau of Labor Statistics (BLS)\n",
    "    * https://www.bls.gov/lau/rdscnp16.htm\n",
    "  \n",
    "* **Variables definitions:**\n",
    "  \n",
    "  * $\\text{GDP\\_GROWTH = The average annual percentage change in GDP in the state}$\n",
    "  * $\\text{UNEMPLOYED = The average annual unemployment rate in the state}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Import and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>...</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>160396.4</td>\n",
       "      <td>166531.8</td>\n",
       "      <td>168695.3</td>\n",
       "      <td>168448.3</td>\n",
       "      <td>172430.4</td>\n",
       "      <td>178040.0</td>\n",
       "      <td>189913.7</td>\n",
       "      <td>197246.5</td>\n",
       "      <td>...</td>\n",
       "      <td>206070.0</td>\n",
       "      <td>208950.3</td>\n",
       "      <td>212862.8</td>\n",
       "      <td>216615.5</td>\n",
       "      <td>220808.8</td>\n",
       "      <td>225272.8</td>\n",
       "      <td>222288.8</td>\n",
       "      <td>233726.6</td>\n",
       "      <td>238556.5</td>\n",
       "      <td>245354.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>41071.0</td>\n",
       "      <td>40263.7</td>\n",
       "      <td>39783.1</td>\n",
       "      <td>38428.1</td>\n",
       "      <td>40014.4</td>\n",
       "      <td>41904.7</td>\n",
       "      <td>41235.0</td>\n",
       "      <td>42880.1</td>\n",
       "      <td>44406.8</td>\n",
       "      <td>...</td>\n",
       "      <td>53303.3</td>\n",
       "      <td>53681.1</td>\n",
       "      <td>53463.9</td>\n",
       "      <td>53550.9</td>\n",
       "      <td>52479.6</td>\n",
       "      <td>52377.5</td>\n",
       "      <td>50332.8</td>\n",
       "      <td>51454.1</td>\n",
       "      <td>50767.1</td>\n",
       "      <td>54059.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>180293.9</td>\n",
       "      <td>197492.1</td>\n",
       "      <td>214293.9</td>\n",
       "      <td>224729.3</td>\n",
       "      <td>230885.6</td>\n",
       "      <td>238257.1</td>\n",
       "      <td>253743.1</td>\n",
       "      <td>264990.0</td>\n",
       "      <td>283806.2</td>\n",
       "      <td>...</td>\n",
       "      <td>301721.2</td>\n",
       "      <td>308582.8</td>\n",
       "      <td>319008.4</td>\n",
       "      <td>333099.0</td>\n",
       "      <td>346398.3</td>\n",
       "      <td>359576.7</td>\n",
       "      <td>365027.7</td>\n",
       "      <td>395035.9</td>\n",
       "      <td>410228.4</td>\n",
       "      <td>422399.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>87180.3</td>\n",
       "      <td>89905.3</td>\n",
       "      <td>94756.9</td>\n",
       "      <td>95509.8</td>\n",
       "      <td>95528.7</td>\n",
       "      <td>98556.6</td>\n",
       "      <td>102948.0</td>\n",
       "      <td>108581.8</td>\n",
       "      <td>112451.1</td>\n",
       "      <td>...</td>\n",
       "      <td>121409.4</td>\n",
       "      <td>121532.5</td>\n",
       "      <td>123034.9</td>\n",
       "      <td>123882.6</td>\n",
       "      <td>126371.2</td>\n",
       "      <td>127220.0</td>\n",
       "      <td>128340.9</td>\n",
       "      <td>137463.6</td>\n",
       "      <td>139560.7</td>\n",
       "      <td>142860.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>1441226.4</td>\n",
       "      <td>1538612.3</td>\n",
       "      <td>1655438.5</td>\n",
       "      <td>1784320.6</td>\n",
       "      <td>1784567.7</td>\n",
       "      <td>1821509.5</td>\n",
       "      <td>1895287.6</td>\n",
       "      <td>1956745.5</td>\n",
       "      <td>2042141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2428675.7</td>\n",
       "      <td>2545979.5</td>\n",
       "      <td>2623711.7</td>\n",
       "      <td>2740550.3</td>\n",
       "      <td>2850970.3</td>\n",
       "      <td>2969609.0</td>\n",
       "      <td>2933320.2</td>\n",
       "      <td>3154188.6</td>\n",
       "      <td>3184007.8</td>\n",
       "      <td>3248656.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state       1997       1998       1999       2000       2001  \\\n",
       "0     Alabama   154700.0   160396.4   166531.8   168695.3   168448.3   \n",
       "1      Alaska    41071.0    40263.7    39783.1    38428.1    40014.4   \n",
       "2     Arizona   180293.9   197492.1   214293.9   224729.3   230885.6   \n",
       "3    Arkansas    87180.3    89905.3    94756.9    95509.8    95528.7   \n",
       "4  California  1441226.4  1538612.3  1655438.5  1784320.6  1784567.7   \n",
       "\n",
       "        2002       2003       2004       2005  ...       2014       2015  \\\n",
       "0   172430.4   178040.0   189913.7   197246.5  ...   206070.0   208950.3   \n",
       "1    41904.7    41235.0    42880.1    44406.8  ...    53303.3    53681.1   \n",
       "2   238257.1   253743.1   264990.0   283806.2  ...   301721.2   308582.8   \n",
       "3    98556.6   102948.0   108581.8   112451.1  ...   121409.4   121532.5   \n",
       "4  1821509.5  1895287.6  1956745.5  2042141.0  ...  2428675.7  2545979.5   \n",
       "\n",
       "        2016       2017       2018       2019       2020       2021  \\\n",
       "0   212862.8   216615.5   220808.8   225272.8   222288.8   233726.6   \n",
       "1    53463.9    53550.9    52479.6    52377.5    50332.8    51454.1   \n",
       "2   319008.4   333099.0   346398.3   359576.7   365027.7   395035.9   \n",
       "3   123034.9   123882.6   126371.2   127220.0   128340.9   137463.6   \n",
       "4  2623711.7  2740550.3  2850970.3  2969609.0  2933320.2  3154188.6   \n",
       "\n",
       "        2022       2023  \n",
       "0   238556.5   245354.7  \n",
       "1    50767.1    54059.7  \n",
       "2   410228.4   422399.6  \n",
       "3   139560.7   142860.6  \n",
       "4  3184007.8  3248656.6  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandasgui import show\n",
    "\n",
    "# 1. Import data\n",
    "gdp_path = r\"E:\\USA auditor turnover data\\usa state-level gdp and unemployment rate\\State GDP\\1997-2023_USA_STATE_GDP.csv\"\n",
    "unemployment_path = r\"E:\\USA auditor turnover data\\usa state-level gdp and unemployment rate\\state unemployment rate\\1995-2023_USA_ANNUAL_STATE_UNEMPLOYMENT_RATE_RAW.xlsx\"\n",
    "\n",
    "df_gdp = pd.read_csv(gdp_path)\n",
    "df_unemployment = pd.read_excel(unemployment_path)\n",
    "\n",
    "df_gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>unemployment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1976</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1976</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>1976</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1976</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>1976</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  year  unemployment_rate\n",
       "0     Alabama  1976                6.7\n",
       "1      Alaska  1976                7.6\n",
       "2     Arizona  1976                9.8\n",
       "3    Arkansas  1976                6.9\n",
       "4  California  1976                9.2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Build `GDP_GROWTH` variable\n",
    "* Reshape df_gdp to build panel data\n",
    "* Calculate the year-over-year percentage change in GDP for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>gdp</th>\n",
       "      <th>GDP_GROWTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1997</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1998</td>\n",
       "      <td>160396.4</td>\n",
       "      <td>0.036822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1999</td>\n",
       "      <td>166531.8</td>\n",
       "      <td>0.038251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2000</td>\n",
       "      <td>168695.3</td>\n",
       "      <td>0.012992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2001</td>\n",
       "      <td>168448.3</td>\n",
       "      <td>-0.001464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  year       gdp  GDP_GROWTH\n",
       "0  Alabama  1997  154700.0         NaN\n",
       "1  Alabama  1998  160396.4    0.036822\n",
       "2  Alabama  1999  166531.8    0.038251\n",
       "3  Alabama  2000  168695.3    0.012992\n",
       "4  Alabama  2001  168448.3   -0.001464"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reshape df_gdp into panel data\n",
    "# 1. Standardize state name and year\n",
    "df_gdp['state'] = df_gdp['state'].str.title()\n",
    "\n",
    "# 2. Use .melt()to turn year row into one column\n",
    "df_gdp_panel = pd.melt(df_gdp, id_vars=['state'], var_name='year', value_name='gdp')\n",
    "df_gdp_panel['year'] = df_gdp_panel['year'].astype(int)\n",
    "\n",
    "# 3. Resort data by state-year\n",
    "df_gdp_panel = df_gdp_panel.sort_values(by=['state', 'year']).reset_index(drop=True)\n",
    "\n",
    "# 4. Generate GDP_GROWTH\n",
    "df_gdp_panel['GDP_GROWTH'] = df_gdp_panel.groupby('state')['gdp'].pct_change() \n",
    "df_gdp_panel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Build `UNEMPLOYED` variable\n",
    "* Sort df_unemployment to build panel data\n",
    "* Notes:\n",
    "  * The original data provide from BLS is exact the average annual unemployment rate for each states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>UNEMPLOYED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1997</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1998</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1999</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2001</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2014</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  year  UNEMPLOYED\n",
       "0    Alabama  1997         4.9\n",
       "1    Alabama  1998         4.5\n",
       "2    Alabama  1999         4.7\n",
       "3    Alabama  2000         4.6\n",
       "4    Alabama  2001         5.2\n",
       "..       ...   ...         ...\n",
       "95  Arkansas  2011         7.9\n",
       "96  Arkansas  2012         7.3\n",
       "97  Arkansas  2013         7.1\n",
       "98  Arkansas  2014         5.9\n",
       "99  Arkansas  2015         5.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort state unemployment rate data\n",
    "df_unemployment_sorted = df_unemployment.sort_values(by=['state', 'year']).reset_index(drop=True)\n",
    "\n",
    "df_unemployment_sorted['year'] = df_unemployment_sorted['year'].astype(int)\n",
    "\n",
    "# Rename the variable\n",
    "df_unemployment_sorted = df_unemployment_sorted.rename(columns={\n",
    "    'unemployment_rate' : 'UNEMPLOYED'\n",
    "})\n",
    "\n",
    "df_unemployment_sorted = df_unemployment_sorted[df_unemployment_sorted['year'] >= 1997]\n",
    "df_unemployment_sorted = df_unemployment_sorted.sort_values(by=['state', 'year']).reset_index(drop=True)\n",
    "\n",
    "df_unemployment_sorted.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Append GDP and unemployment variables into office-year panel, and reorder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to merge office-year\n",
      "_merge\n",
      "both          6402\n",
      "right_only     619\n",
      "left_only      119\n",
      "Name: count, dtype: int64\n",
      "_merge\n",
      "both          6402\n",
      "right_only     457\n",
      "left_only        0\n",
      "Name: count, dtype: int64\n",
      "start to merge office-year filtered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_merge\n",
      "both          5497\n",
      "right_only     644\n",
      "left_only      104\n",
      "Name: count, dtype: int64\n",
      "_merge\n",
      "both          5497\n",
      "right_only     482\n",
      "left_only        0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def merge_dataframe(df_left, df_right):\n",
    "    df_left['state'] = df_left['state'].astype(str)\n",
    "    df_right['state'] = df_right['state'].astype(str)\n",
    "\n",
    "    df_left['year'] = df_left['year'].astype(int)\n",
    "    df_right['year'] = df_right['year'].astype(int)\n",
    "\n",
    "    df_merge = df_left.merge(df_right,\n",
    "                                left_on=['state', 'year'], \n",
    "                                right_on =['state', 'year'] ,\n",
    "                                how='outer',\n",
    "                                indicator=True)\n",
    "\n",
    "    merge_report = df_merge['_merge'].value_counts()\n",
    "    print(merge_report) \n",
    "\n",
    "    df_merge = df_merge[df_merge['_merge'] == 'both']\n",
    "    df_merge = df_merge.drop(columns = ['_merge'])\n",
    "    \n",
    "    return df_merge\n",
    "\n",
    "def reorder_dataframe(df):\n",
    "    # Define the columns to move to the beginning\n",
    "    cols_to_move = ['office_key_location', \n",
    "                    'office_fullname', \n",
    "                    'year',\n",
    "                    'HIRED_AUDITORS_NUM',\n",
    "                    'IN_FLOW_RATE',\n",
    "                    'OUT_FLOW_RATE',\n",
    "                    'NET_FLOW_RATE',\n",
    "                    'IN_FLOW_RATE_EMP',\n",
    "                    'OUT_FLOW_RATE_EMP',\n",
    "                    'NET_FLOW_RATE_EMP',                    \n",
    "                    'OFFICE_SIZE',\n",
    "                    'LARGE_OFFICE',\n",
    "                    'MARKET_SHARE',\n",
    "                    'HIGH_SALARY',\n",
    "                    'RESTATE_PERC',\n",
    "                    'MSA_OFFICES',\n",
    "                    'OFFICE_GROWTH_NUMBERS',\n",
    "                    'OFFICE_GROWTH_FEES',\n",
    "                    'HIGH_GROWTH',\n",
    "                    'UNEMPLOYED',\n",
    "                    'GDP_GROWTH',\n",
    "                    'COMBINED_OP_INDICATOR',\n",
    "                    'COMBINED_OP_RATE',\n",
    "                    'gap_indicator_revelio',\n",
    "                    'gap_indicator_aa',\n",
    "                    'copy_2004_indicator',\n",
    "                    'metro_area', \n",
    "                    'city',\n",
    "                    'state'\n",
    "                    ] \n",
    "    # Get the remaining columns (excluding those moved)\n",
    "    remaining_cols = [col for col in df.columns if col not in cols_to_move]\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[cols_to_move + remaining_cols]\n",
    "\n",
    "    return df\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Start to merge office-year\")\n",
    "    df_office_year = merge_dataframe(df_office_year, df_gdp_panel)\n",
    "    df_office_year = merge_dataframe(df_office_year, df_unemployment_sorted)\n",
    "    df_office_year = reorder_dataframe(df_office_year)\n",
    "\n",
    "    print(\"start to merge office-year filtered\")\n",
    "    df_office_year_filtered = merge_dataframe(df_office_year_filtered, df_gdp_panel)  \n",
    "    df_office_year_filtered = merge_dataframe(df_office_year_filtered, df_unemployment_sorted)  \n",
    "    df_office_year_filtered = reorder_dataframe(df_office_year_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Save the office-year panel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['office_key_location', 'office_fullname', 'year', 'HIRED_AUDITORS_NUM',\n",
      "       'IN_FLOW_RATE', 'OUT_FLOW_RATE', 'NET_FLOW_RATE', 'IN_FLOW_RATE_EMP',\n",
      "       'OUT_FLOW_RATE_EMP', 'NET_FLOW_RATE_EMP', 'OFFICE_SIZE', 'LARGE_OFFICE',\n",
      "       'MARKET_SHARE', 'HIGH_SALARY', 'RESTATE_PERC', 'MSA_OFFICES',\n",
      "       'OFFICE_GROWTH_NUMBERS', 'OFFICE_GROWTH_FEES', 'HIGH_GROWTH',\n",
      "       'UNEMPLOYED', 'GDP_GROWTH', 'COMBINED_OP_INDICATOR', 'COMBINED_OP_RATE',\n",
      "       'gap_indicator_revelio', 'gap_indicator_aa', 'copy_2004_indicator',\n",
      "       'metro_area', 'city', 'state', 'office_id', 'metro_id', 'flow_in',\n",
      "       'flow_out', 'net_flow', 'gap_indicator_revelio_row', 'total_employees',\n",
      "       'office_avg_salary', 'metro_median_salary', 'TOTAL_RESTATEMENT',\n",
      "       'TOTAL_AUDIT_FEE', 'TOTAL_COMBINED_IC', 'TOTAL_REPORTS',\n",
      "       'gap_indicator_aa_row', 'BIG4_flag', 'median_office_size',\n",
      "       'total_big4_clients', 'gdp'],\n",
      "      dtype='object')\n",
      "Index(['office_key_location', 'office_fullname', 'year', 'HIRED_AUDITORS_NUM',\n",
      "       'IN_FLOW_RATE', 'OUT_FLOW_RATE', 'NET_FLOW_RATE', 'IN_FLOW_RATE_EMP',\n",
      "       'OUT_FLOW_RATE_EMP', 'NET_FLOW_RATE_EMP', 'OFFICE_SIZE', 'LARGE_OFFICE',\n",
      "       'MARKET_SHARE', 'HIGH_SALARY', 'RESTATE_PERC', 'MSA_OFFICES',\n",
      "       'OFFICE_GROWTH_NUMBERS', 'OFFICE_GROWTH_FEES', 'HIGH_GROWTH',\n",
      "       'UNEMPLOYED', 'GDP_GROWTH', 'COMBINED_OP_INDICATOR', 'COMBINED_OP_RATE',\n",
      "       'gap_indicator_revelio', 'gap_indicator_aa', 'copy_2004_indicator',\n",
      "       'metro_area', 'city', 'state', 'office_id', 'metro_id', 'flow_in',\n",
      "       'flow_out', 'net_flow', 'gap_indicator_revelio_row', 'total_employees',\n",
      "       'office_avg_salary', 'metro_median_salary', 'TOTAL_RESTATEMENT',\n",
      "       'TOTAL_AUDIT_FEE', 'TOTAL_COMBINED_IC', 'TOTAL_REPORTS',\n",
      "       'gap_indicator_aa_row', 'BIG4_flag', 'median_office_size',\n",
      "       'total_big4_clients', 'gdp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_office_year.columns)\n",
    "print(df_office_year_filtered.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Marking Raw Records in the Dataset\n",
    "* rev_raw_office: Set to 1 if an audit office has no discontinued records (i.e., both gap_indicator_revelio and gap_indicator_aa equal 0); otherwise, set to 0.\n",
    "* rev_raw_row: Set to 1 if a row is not inferred (i.e., if gap_indicator_revelio_raw, gap_indicator_aa_row, and copy_2004_indicator are all 0); otherwise, set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create 'rev_raw_office'\n",
    "\n",
    "df_office_year['rev_raw_office'] = 0  # Initialize the column with 0\n",
    "mask = (\n",
    "    (df_office_year['gap_indicator_revelio'] == 0) & \n",
    "    (df_office_year['gap_indicator_aa'] == 0) \n",
    ")\n",
    "df_office_year.loc[mask, 'rev_raw_office'] = 1\n",
    "\n",
    "df_office_year_filtered['rev_raw_office'] = 0  # Initialize the column with 0\n",
    "mask = (\n",
    "    (df_office_year_filtered['gap_indicator_revelio'] == 0) & \n",
    "    (df_office_year_filtered['gap_indicator_aa'] == 0) \n",
    ")\n",
    "df_office_year_filtered.loc[mask, 'rev_raw_office'] = 1\n",
    "\n",
    "# 2. Create 'rev_raw_row'\n",
    "df_office_year['rev_raw_row'] = 0  # Initialize the column with 0\n",
    "mask = (\n",
    "    (df_office_year['gap_indicator_revelio_row'] == 0) & \n",
    "    (df_office_year['gap_indicator_aa_row'] == 0) &\n",
    "    (df_office_year['copy_2004_indicator'] == 0) \n",
    ")\n",
    "df_office_year.loc[mask, 'rev_raw_row'] = 1\n",
    "\n",
    "df_office_year_filtered['rev_raw_row'] = 0  # Initialize the column with 0\n",
    "mask = (\n",
    "    (df_office_year_filtered['gap_indicator_revelio_row'] == 0) & \n",
    "    (df_office_year_filtered['gap_indicator_aa_row'] == 0) &\n",
    "    (df_office_year_filtered['copy_2004_indicator'] == 0) \n",
    ")\n",
    "df_office_year_filtered.loc[mask, 'rev_raw_row'] = 1\n",
    "\n",
    "# 3. Reorder the columns\n",
    "# 3.1 Define the reorder function\n",
    "def reorder_dataframe(df):\n",
    "    # Define the columns to move to the beginning\n",
    "    cols_to_move = ['office_key_location', \n",
    "                    'office_fullname', \n",
    "                    'year',\n",
    "                    'HIRED_AUDITORS_NUM',\n",
    "                    'IN_FLOW_RATE',\n",
    "                    'OUT_FLOW_RATE',\n",
    "                    'NET_FLOW_RATE',\n",
    "                    'IN_FLOW_RATE_EMP',\n",
    "                    'OUT_FLOW_RATE_EMP',\n",
    "                    'NET_FLOW_RATE_EMP',                    \n",
    "                    'OFFICE_SIZE',\n",
    "                    'LARGE_OFFICE',\n",
    "                    'MARKET_SHARE',\n",
    "                    'HIGH_SALARY',\n",
    "                    'RESTATE_PERC',\n",
    "                    'MSA_OFFICES',\n",
    "                    'OFFICE_GROWTH_NUMBERS',\n",
    "                    'OFFICE_GROWTH_FEES',\n",
    "                    'HIGH_GROWTH',\n",
    "                    'UNEMPLOYED',\n",
    "                    'GDP_GROWTH',\n",
    "                    'COMBINED_OP_INDICATOR',\n",
    "                    'COMBINED_OP_RATE',\n",
    "                    'rev_raw_office',\n",
    "                    'rev_raw_row',\n",
    "                    'gap_indicator_revelio',\n",
    "                    'gap_indicator_revelio_row',\n",
    "                    'gap_indicator_aa',\n",
    "                    'gap_indicator_aa_row',\n",
    "                    'copy_2004_indicator',\n",
    "                    'metro_area', \n",
    "                    'city',\n",
    "                    'state'\n",
    "                    ] \n",
    "    # Get the remaining columns (excluding those moved)\n",
    "    remaining_cols = [col for col in df.columns if col not in cols_to_move]\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[cols_to_move + remaining_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "# 3.2 Apply the reorder function\n",
    "df_office_year = reorder_dataframe(df_office_year)\n",
    "df_office_year_filtered = reorder_dataframe(df_office_year_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(df_office_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Save the office-year panel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path1 = r\"E:\\USA auditor turnover data\\result data\\office-year panel date_final.csv\"\n",
    "save_path2 = r\"E:\\USA auditor turnover data\\result data\\office-year panel date_filtered_final.csv\"\n",
    "\n",
    "df_office_year = df_office_year.sort_values(by=['office_key_location', 'year'])\n",
    "df_office_year_filtered = df_office_year_filtered.sort_values(by=['office_key_location', 'year'])\n",
    "\n",
    "df_office_year.to_csv(save_path1, index=False)\n",
    "df_office_year_filtered.to_csv(save_path2, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
