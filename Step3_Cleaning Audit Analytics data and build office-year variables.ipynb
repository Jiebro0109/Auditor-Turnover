{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build office level variables form Audit Analytics dataset\n",
    "* Jie Xia, SUSTech\n",
    "* 2025-02-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cleaning data\n",
    "* Drop rows where have missing value\n",
    "* Standardize city expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Drop NaN and standardize city expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasgui import show\n",
    "import re\n",
    "\n",
    "### Cleaning Data\n",
    "\n",
    "# 1. Import Audit Analytics (AA) data\n",
    "input_path = r\"e:\\USA auditor turnover data\\Audit Analytics data\\AuditAnalytics_us_cleaned_for_python.dta\"\n",
    "df_aa = pd.read_stata(input_path)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "original_length = len(df_aa)\n",
    "df_aa = df_aa.dropna()\n",
    "dropped_rows = original_length - len(df_aa)\n",
    "print(f\"{dropped_rows} rows have been dropped due to missing values\")\n",
    "\n",
    "# Standardize city names by renaming \"Washington\" to \"Washington DC\"\n",
    "mask = df_aa['AUD_CITY'].str.strip().str.lower() == 'washington'\n",
    "df_aa.loc[mask, 'AUD_CITY'] = 'Washington DC'\n",
    "\n",
    "mask = df_aa['BUS_CITY_TITLE'].str.strip().str.lower() == 'washington'\n",
    "df_aa.loc[mask, 'BUS_CITY_TITLE'] = 'Washington DC'\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans a text string by removing punctuation and extra whitespace.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):  # Handle NaN values\n",
    "        return text\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Replace punctuation with a space\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())  # Remove extra spaces and special characters\n",
    "    return text.strip()\n",
    "\n",
    "# Apply text cleaning to the 'AUD_CITY' column\n",
    "df_aa['AUD_CITY'] = df_aa['AUD_CITY'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_aa.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Generate indicator and drop duplicates\n",
    "1. Create Office-City Identifier:\n",
    "\n",
    "   * Convert key numeric columns to integer.\n",
    "   * Combine AUDITOR_FKEY, AUD_CITY, and AUD_STATE_NAME (all title-cased) into a single identifier office_key_location.\n",
    "  \n",
    "2. Reorder Columns:\n",
    "\n",
    "   * Move important columns (e.g., office_key_location, OP_AUD_NAME, etc.) to the beginning of the DataFrame.\n",
    "  \n",
    "3. Sort Data:\n",
    "\n",
    "   * Sort observations by office_key_location, year (FY_IC_OP), and client (COMPANY_FKEY).\n",
    "\n",
    "4. Identify BIG 4 Firms:\n",
    "\n",
    "   * Create an indicator (BIG4_flag) that marks a record as 1 if the office name contains any of the BIG 4 firm names.\n",
    "  \n",
    "5. Remove Duplicate Client Records:\n",
    "\n",
    "   * Within each office and year, sort by IS_NTH_RESTATE (in descending order) and drop duplicates for the same client.\n",
    "   * This ensures that if multiple records exist, the one with a non-zero restatement is retained (if available).\n",
    "  \n",
    "6. Resort the Cleaned DataFrame:\n",
    "\n",
    "   * Finally, re-sort the cleaned DataFrame by office_key_location, FY_IC_OP, and COMPANY_FKEY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create office-city level identifier 'office_key_location' (combination of AUDITOR_FKEY, city, state)\n",
    "df_aa['AUDITOR_FKEY'] = df_aa['AUDITOR_FKEY'].astype(int)\n",
    "df_aa['FY_IC_OP'] = df_aa['FY_IC_OP'].astype(int)\n",
    "df_aa['IS_NTH_RESTATE'] = df_aa['IS_NTH_RESTATE'].astype(int)\n",
    "df_aa['AUDIT_FEES'] = df_aa['AUDIT_FEES'].astype(int)\n",
    "\n",
    "# Combine AUDITOR_FKEY, AUD_CITY, and AUD_STATE_NAME into a single identifier, with proper title casing and commas\n",
    "df_aa['office_key_location'] = (\n",
    "    df_aa['AUDITOR_FKEY'].astype(str).str.title() + ', ' +\n",
    "    df_aa['AUD_CITY'].str.title() + ', ' +\n",
    "    df_aa['AUD_STATE_NAME'].str.title()\n",
    ")\n",
    "\n",
    "# 3. Reorder the columns\n",
    "# Define the columns to be moved to the beginning\n",
    "cols_to_move = [\n",
    "    'office_key_location', \n",
    "    \"OP_AUD_NAME\",\n",
    "    \"FY_IC_OP\",\n",
    "    \"NAME\",\n",
    "    \"IS_NTH_RESTATE\",\n",
    "    \"AUDIT_FEES\"\n",
    "]\n",
    "# Get the remaining columns that are not in cols_to_move\n",
    "remaining_cols = [col for col in df_aa.columns if col not in cols_to_move]\n",
    "# Reorder the DataFrame so that cols_to_move come first\n",
    "df_aa = df_aa[cols_to_move + remaining_cols]\n",
    "\n",
    "# 4. Sort observations by office_key_location, year (FY_IC_OP), and client (COMPANY_FKEY)\n",
    "df_aa = df_aa.sort_values(by=['office_key_location', 'FY_IC_OP', 'COMPANY_FKEY'])\n",
    "\n",
    "# 5. Build an indicator for BIG 4 accounting firms\n",
    "big4_names = [\"PricewaterhouseCoopers\", \"Ernst & Young\", \"Deloitte & Touche\", \"KPMG\"]\n",
    "\n",
    "def is_big4(office_name):\n",
    "    \"\"\"\n",
    "    Returns 1 if the office name contains any of the BIG 4 names (case insensitive), else returns 0.\n",
    "    \"\"\"\n",
    "    if pd.isna(office_name):\n",
    "        return 0\n",
    "    for name in big4_names:\n",
    "        if name.lower() in office_name.lower():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df_aa['BIG4_flag'] = df_aa['OP_AUD_NAME'].apply(is_big4)\n",
    "\n",
    "# 6. For each office_key_location & year, remove duplicate client records.\n",
    "#    If multiple records exist for the same client within the same office and year,\n",
    "#    then if any record has a non-zero restatement (IS_NTH_RESTATE != 0), keep that record;\n",
    "#    otherwise, keep just one record.\n",
    "#    This is achieved by sorting in descending order by IS_NTH_RESTATE and then dropping duplicates.\n",
    "df_aa = df_aa.sort_values(by='IS_NTH_RESTATE', ascending=False)\n",
    "df_aa_clean = df_aa.drop_duplicates(subset=['office_key_location', 'FY_IC_OP', 'COMPANY_FKEY'])\n",
    "\n",
    "# 7. Resort the cleaned DataFrame by office_key_location, year, and client\n",
    "df_aa_clean = df_aa_clean.sort_values(by=['office_key_location', 'FY_IC_OP', 'COMPANY_FKEY'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Check the AA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Describe BIG4 distribution in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big4_df = df_aa_clean[df_aa_clean['BIG4_flag'] == 1]\n",
    "\n",
    "big4_number = big4_df['office_key_location'].nunique()\n",
    "total_number = df_aa_clean['office_key_location'].nunique()\n",
    "\n",
    "print(f\"{big4_number} offices are big4\\n\"\n",
    "      f\"{total_number - big4_number} offices are non-big4\\n\"\n",
    "      f\"{big4_number / total_number} % of office is big4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Check change of COMBINED_IC_OP in office-client-year\n",
    "\n",
    "1. Convert Year Column:\n",
    "\n",
    "   * Ensure the FY_IC_OP column (representing the year) is of integer type.\n",
    "2. Define Window Check Function:\n",
    "\n",
    "   * The function check_window is applied to each group (grouped by office_key_location and COMPANY_FKEY).\n",
    "   * For each record within a group, it looks at a window of years (current year Â± window) and checks if COMBINED_IC_OP remains consistent (i.e., has only one unique value).\n",
    "   * A new flag column (e.g., flag_2_year, flag_3_year, or flag_5_year) is created, where 1 indicates consistency and 0 indicates inconsistency.\n",
    "3. Apply Window Check for Various Windows:\n",
    "\n",
    "   * The check_window function is applied for window lengths of 2, 3, and 5 years using a groupby-apply operation.\n",
    "4. Assess Overall Client Consistency:\n",
    "\n",
    "   * The function client_consistency aggregates the window flag for each group (client within an office) over the entire sample period.\n",
    "   * If the flag is 1 for all records within the group for a given window, the overall flag is set to 1; otherwise, it is 0.\n",
    "5. Compute and Display Client Consistency:\n",
    "\n",
    "   * For each window (2, 3, 5 years), the overall consistency is computed for each client group.\n",
    "   * The code then prints out the counts of clients that maintained consistency within each window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dataframe(df):\n",
    "    # Define the columns to move to the beginning\n",
    "    cols_to_move = ['office_key_location',\n",
    "                    'COMPANY_FKEY',\n",
    "                    'FY_IC_OP',\n",
    "                    'COMBINED_IC_OP'\n",
    "                    ] \n",
    "    # Get the remaining columns (excluding those moved)\n",
    "    remaining_cols = [col for col in df.columns if col not in cols_to_move]\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[cols_to_move + remaining_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df_check_aa = df_aa.sort_values(by=['office_key_location', 'COMPANY_FKEY','FY_IC_OP',])\n",
    "\n",
    "df_check_aa = reorder_dataframe(df_check_aa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume FY_IC_OP is the year column (integer type); convert if necessary\n",
    "df_check_aa['FY_IC_OP'] = df_check_aa['FY_IC_OP'].astype(int)\n",
    "\n",
    "def check_window(group, window):\n",
    "    \"\"\"\n",
    "    For each group (i.e., a unique audit office-client combination),\n",
    "    check whether the value of COMBINED_IC_OP remains consistent within a window\n",
    "    defined as (current year Â± window). For each record in the group,\n",
    "    return 1 if the COMBINED_IC_OP value is the same across the window, otherwise return 0.\n",
    "    \"\"\"\n",
    "    # Sort the group by year\n",
    "    group = group.sort_values('FY_IC_OP').copy()\n",
    "    # Define a new column name based on the window, e.g., 'flag_2_year'\n",
    "    flag_column = f'flag_{window}_year'\n",
    "    \n",
    "    # For each row, compute whether COMBINED_IC_OP is unique within the specified window\n",
    "    group[flag_column] = group.apply(\n",
    "        lambda row: 1 if group[\n",
    "            (group['FY_IC_OP'] >= row['FY_IC_OP'] - window) &\n",
    "            (group['FY_IC_OP'] <= row['FY_IC_OP'] + window)\n",
    "        ]['COMBINED_IC_OP'].nunique() == 1 else 0, \n",
    "        axis=1\n",
    "    )\n",
    "    return group\n",
    "\n",
    "# Apply the window check for different window lengths (2, 3, and 5 years)\n",
    "for window in [2, 3, 5]:\n",
    "    df_check_aa = df_check_aa.groupby(\n",
    "        ['office_key_location', 'COMPANY_FKEY'], group_keys=False\n",
    "    ).apply(lambda g: check_window(g, window))\n",
    "\n",
    "def client_consistency(group, window):\n",
    "    \"\"\"\n",
    "    For each group (i.e., a unique audit office-client combination),\n",
    "    check whether the COMBINED_IC_OP value remains consistent within the given window \n",
    "    across all records. If every record in the group has a flag of 1 for the specified window,\n",
    "    then the overall flag is set to 1; otherwise, it is 0.\n",
    "    \"\"\"\n",
    "    flag_column = f'flag_{window}_year'\n",
    "    overall_flag = 1 if group[flag_column].min() == 1 else 0\n",
    "    return pd.Series({flag_column: overall_flag})\n",
    "\n",
    "# Compute overall client consistency for each window length\n",
    "client_flags = {}\n",
    "for window in [2, 3, 5]:\n",
    "    flag_column = f'flag_{window}_year'\n",
    "    client_flags[flag_column] = df_check_aa.groupby(\n",
    "        ['office_key_location', 'COMPANY_FKEY']\n",
    "    ).apply(lambda g: client_consistency(g, window)).reset_index()\n",
    "\n",
    "# Display the results: number of clients with consistent COMBINED_IC_OP within each window\n",
    "for window in [2, 3, 5]:\n",
    "    flag_column = f'flag_{window}_year'\n",
    "    print(f\"Number of clients with consistent COMBINED_IC_OP within a Â±{window}-year window:\")\n",
    "    counts = client_flags[flag_column][flag_column].value_counts()\n",
    "    print(counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Group the data by office_key_location and COMPANY_FKEY, flag each group as 1 if its COMBINED_IC_OP values are consistent (or 0 otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group df_check_aa by office_key_location and COMPANY_FKEY, and compute whether COMBINED_IC_OP is consistent within each group.\n",
    "# If there is only one unique value of COMBINED_IC_OP in the group, assign flag = 1; otherwise, flag = 0.\n",
    "client_flags = df_check_aa.groupby(['office_key_location', 'COMPANY_FKEY']).apply(\n",
    "    lambda group: 1 if group['COMBINED_IC_OP'].nunique() == 1 else 0\n",
    ").reset_index(name='flag')\n",
    "\n",
    "# Output the flag results for each group\n",
    "print(client_flags.head())\n",
    "\n",
    "# Count the number of clients with each flag (1 and 0)\n",
    "flag_counts = client_flags['flag'].value_counts()\n",
    "print(\"Number of clients with flag 1 and 0:\")\n",
    "print(flag_counts)\n",
    "\n",
    "# Print the ratio 1431/10845 (as an example)\n",
    "print(1431 / 10845)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build office-level variables panel data\n",
    "\n",
    "* Variables definitions:\n",
    "  * **Office Size variables**\n",
    "  \n",
    "    * $\\text{OFFICE\\_SIZE} = \\text{Number of audit clients in an audit office in a year}$\n",
    "  \n",
    "    * $\\text{LARGE\\_OFFICE =  if an audit officeâs size is greater than the sample median in an MSA}$\n",
    "  \n",
    "    * $\\text{MARKET\\_RATE} = \\cfrac{\\text{Total number of audit clients in an office in a year}}{\\text{Total number of audit clients for all Big 4 offices in the MSA in a year}}$\n",
    "  \n",
    "    * $\\text{OFFICE\\_GROWTH\\_NUMBERS} = \\text{The percentage change in the number of audit clients in an audit office from year}_{tâ1} \\text{to year}_{t}$\n",
    "  \n",
    "  * **Restatement variables:**\n",
    "  \n",
    "    * $\\text{RESTATE\\_PERC} = \\cfrac{\\text{Number of restatement announcements for clients}}{\\text{Total number of audit clients}}\\  \\text{in office-year}$\n",
    "  \n",
    "  * **Audit Fees variables:**\n",
    "  \n",
    "    * $\\text{OFFICE\\_GROWTH\\_FEES} = \\text{The percentage change in total audit fees in an audit office from year}_{tâ1} \\text{to year}_{t}$\n",
    "\n",
    "    * $\\text{HIGH\\_GROWTH} = \\text{if an officeâs growth in audit fees is greater than the sample median in a year}$\n",
    "\n",
    "  * **Combined internal control varibales:**\n",
    "\n",
    "    * $\\text{COMBINED\\_OP\\_INDICATOR = if an audit office published any financial statement report integrated with internal control opinion in a year}$ \n",
    "\n",
    "    * $\\text{COMBINED\\_OP\\_RATE} = \\cfrac{\\text{Total number of financial statement reports with internal control opinion published by an audit office in a year}}{\\text{Total number of financial statement report published by an audit office in a year}}$ \n",
    "  \n",
    "  * **Gap indicator variables:**\n",
    "    * $\\text{gap\\_indicator\\_aa} = \\text{indicate the audit office if any years of it has an discontinuous record}$\n",
    "    * $\\text{gap\\_indicator\\_aa\\_row} = \\text{indicate the specific gapâfilled rows}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Calculate the variables\n",
    "1. Aggregate Office-Year Metrics:\n",
    "\n",
    "   * Group data by office_key_location and FY_IC_OP to compute:\n",
    "     *  the number of unique clients (OFFICE_SIZE)\n",
    "     *  total restatement (TOTAL_RESTATEMENT)\n",
    "     *  total audit fees (TOTAL_AUDIT_FEE)\n",
    "     *  the ratio of reports with internal control opinion to total reports(COMBINED_OP_RATE)\n",
    "     *  and set to 1 if the office published any report with an internal control opinion, otherwise (COMBINED_OP_INDICATOR)\n",
    "2. Fill Missing Years and Create Gap Indicator(`gap_indicator_aa`/`gap_indicator_aa_row`):\n",
    "\n",
    "   * For each office, generate a complete sequence of years between its minimum and maximum year, merge with the aggregated data (filling missing metrics with 0), and create a `gap_indicator_aa` if any years are missing(i.e., total client == 0 in any year).\n",
    "   * For an office that has ever experienced a discontinuous client history (i.e., total client == 0 in any year), mark its specific gapâfilled rows with 1; otherwise, 0, using `gap_indicator_aa_row`.\n",
    "3. Compute Growth Rates and Restatement Percentage:\n",
    "\n",
    "   * Calculate growth rates for both OFFICE_SIZE (as OFFICE_GROWTH_NUMBERS) and TOTAL_AUDIT_FEE (as OFFICE_GROWTH_FEES) between consecutive years, and compute RESTATE_PERC as the ratio of TOTAL_RESTATEMENT to OFFICE_SIZE when applicable.\n",
    "4. Determine High Growth Offices:\n",
    "\n",
    "   * For each year, compute the median growth rate of TOTAL_AUDIT_FEE and flag an office as HIGH_GROWTH if its growth rate exceeds the median.\n",
    "5. Merge BIG4 Flag:\n",
    "\n",
    "   * Integrate the office-level BIG4_flag from the original cleaned dataset into the aggregated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Calculate Basic Metrics by Grouping on office_key_location and FY_IC_OP:\n",
    "#    - OFFICE_SIZE: Number of unique COMPANY_FKEY (i.e., clients) for each office-year.\n",
    "#    - TOTAL_RESTATEMENT: Sum of IS_NTH_RESTATE.\n",
    "#    - TOTAL_AUDIT_FEE: Sum of AUDIT_FEES.\n",
    "#    - TOTAL_COMBINED_IC: Sum of COMBINED_IC_OP (i.e., number of reports with internal control opinion).\n",
    "#    - TOTAL_REPORTS: Total number of financial statement reports published by the office in that year.\n",
    "# -------------------------------\n",
    "agg = df_aa_clean.groupby(['office_key_location', 'FY_IC_OP']).agg(\n",
    "    OFFICE_SIZE=('COMPANY_FKEY', 'nunique'),\n",
    "    TOTAL_RESTATEMENT=('IS_NTH_RESTATE', 'sum'),\n",
    "    TOTAL_AUDIT_FEE=('AUDIT_FEES', 'sum'),\n",
    "    TOTAL_COMBINED_IC=('COMBINED_IC_OP', 'sum'),\n",
    "    TOTAL_REPORTS=('COMBINED_IC_OP', 'count')  # Assuming each row is one report.\n",
    ").reset_index()\n",
    "\n",
    "# -------------------------------\n",
    "# 1.1 Compute Combined Internal Control Indicators:\n",
    "#     - COMBINED_OP_INDICATOR: 1 if the audit office published any report with an internal control opinion (i.e., TOTAL_COMBINED_IC > 0), otherwise 0.\n",
    "#     - COMBINED_OP_RATE: The ratio of reports with internal control opinion to total reports.\n",
    "# -------------------------------\n",
    "agg['COMBINED_OP_INDICATOR'] = np.where(agg['TOTAL_COMBINED_IC'] > 0, 1, 0)\n",
    "agg['COMBINED_OP_RATE'] = np.where(\n",
    "    agg['TOTAL_REPORTS'] > 0,\n",
    "    agg['TOTAL_COMBINED_IC'] / agg['TOTAL_REPORTS'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Fill in Missing Years for Each Office and Create Gap Indicators:\n",
    "#    For each office_key_location, from its minimum to maximum year,\n",
    "#    fill in records for missing years (with all metric values set to 0).\n",
    "#    Also, if the actual number of years is less than (max - min + 1), mark gap_indicator_aa as 1.\n",
    "#    Additionally, mark the gap-filled row with gap_indicator_aa_row = 1 (and 0 otherwise).\n",
    "# -------------------------------\n",
    "# 2.1 Get the minimum and maximum year for each office\n",
    "office_years = agg.groupby('office_key_location')['FY_IC_OP'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# 2.2 Construct a complete sequence of years for each office\n",
    "full_rows = []\n",
    "for _, row in office_years.iterrows():\n",
    "    office = row['office_key_location']\n",
    "    start_year = int(row['min'])\n",
    "    end_year = int(row['max'])\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        full_rows.append({'office_key_location': office, 'FY_IC_OP': year})\n",
    "full_df = pd.DataFrame(full_rows)\n",
    "\n",
    "# 2.3 Merge the complete year records with the aggregated metrics.\n",
    "#      Use the merge indicator to flag rows that are gap-filled.\n",
    "agg_full = full_df.merge(agg, on=['office_key_location', 'FY_IC_OP'], how='left', indicator='merge_flag')\n",
    "agg_full['gap_indicator_aa_row'] = np.where(agg_full['merge_flag'] == 'left_only', 1, 0)\n",
    "agg_full = agg_full.drop(columns=['merge_flag'])\n",
    "agg_full[['OFFICE_SIZE', 'TOTAL_RESTATEMENT', 'TOTAL_AUDIT_FEE',\n",
    "          'TOTAL_COMBINED_IC', 'TOTAL_REPORTS', 'COMBINED_OP_INDICATOR',\n",
    "          'COMBINED_OP_RATE']] = agg_full[['OFFICE_SIZE', 'TOTAL_RESTATEMENT', 'TOTAL_AUDIT_FEE',\n",
    "                                            'TOTAL_COMBINED_IC', 'TOTAL_REPORTS', 'COMBINED_OP_INDICATOR',\n",
    "                                            'COMBINED_OP_RATE']].fillna(0)\n",
    "\n",
    "# 2.4 Create the GAP_INDICATOR (office-level):\n",
    "#     For each office, if the number of actual years is less than the expected number (max - min + 1), mark gap_indicator_aa = 1; otherwise, 0.\n",
    "office_years['expected_years'] = office_years['max'] - office_years['min'] + 1\n",
    "actual_counts = agg.groupby('office_key_location').size().reset_index(name='actual_years')\n",
    "office_years = office_years.merge(actual_counts, on='office_key_location', how='left')\n",
    "office_years['gap_indicator_aa'] = np.where(office_years['actual_years'] < office_years['expected_years'], 1, 0)\n",
    "agg_full = agg_full.merge(office_years[['office_key_location', 'gap_indicator_aa']], on='office_key_location', how='left')\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Calculate Derived Metrics: Growth Rates and Ratio Indicators\n",
    "# -------------------------------\n",
    "def compute_growth(df, col, new_col):\n",
    "    df = df.sort_values('FY_IC_OP').copy()\n",
    "    df[new_col] = np.nan\n",
    "    df['prev_year'] = df['FY_IC_OP'].shift(1)\n",
    "    df['prev_val'] = df[col].shift(1)\n",
    "    df[new_col] = np.where(\n",
    "        ((df['FY_IC_OP'] - df['prev_year'] == 1) & (df['prev_val'] != 0)),\n",
    "        (df[col] - df['prev_val']) / df['prev_val'],\n",
    "        np.nan\n",
    "    )\n",
    "    return df.drop(columns=['prev_year', 'prev_val'])\n",
    "\n",
    "# Calculate growth rate for OFFICE_SIZE\n",
    "agg_full = agg_full.sort_values(['office_key_location', 'FY_IC_OP'])\n",
    "agg_full = agg_full.groupby('office_key_location').apply(lambda x: compute_growth(x, 'OFFICE_SIZE', 'OFFICE_GROWTH_NUMBERS')).reset_index(drop=True)\n",
    "\n",
    "# Calculate growth rate for TOTAL_AUDIT_FEE\n",
    "agg_full = agg_full.sort_values(['office_key_location', 'FY_IC_OP'])\n",
    "agg_full = agg_full.groupby('office_key_location').apply(lambda x: compute_growth(x, 'TOTAL_AUDIT_FEE', 'OFFICE_GROWTH_FEES')).reset_index(drop=True)\n",
    "\n",
    "# Calculate RESTATE_PERC: If OFFICE_SIZE > 0, then ratio = TOTAL_RESTATEMENT / OFFICE_SIZE; otherwise, set to NaN.\n",
    "agg_full['RESTATE_PERC'] = np.where(agg_full['OFFICE_SIZE'] > 0,\n",
    "                                    agg_full['TOTAL_RESTATEMENT'] / agg_full['OFFICE_SIZE'],\n",
    "                                    np.nan)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Compute HIGH_GROWTH Indicator:\n",
    "#    For each year, compute the median of TOTAL_AUDIT_FEE growth rates across all offices.\n",
    "#    Then, if an office's growth rate for that year is above the median, mark HIGH_GROWTH as 1; otherwise, 0.\n",
    "# -------------------------------\n",
    "median_growth = agg_full.groupby('FY_IC_OP')['OFFICE_GROWTH_FEES'].median().reset_index().rename(\n",
    "    columns={'OFFICE_GROWTH_FEES': 'MEDIAN_GROWTH_FEES'}\n",
    ")\n",
    "agg_full = agg_full.merge(median_growth, on='FY_IC_OP', how='left')\n",
    "agg_full['HIGH_GROWTH'] = np.where(\n",
    "    (agg_full['OFFICE_GROWTH_FEES'].notna()) & (agg_full['OFFICE_GROWTH_FEES'] > agg_full['MEDIAN_GROWTH_FEES']),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "agg_full = agg_full.drop(columns=['MEDIAN_GROWTH_FEES'])\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Merge BIG4_flag (Office-Level Indicator):\n",
    "#    Retrieve the unique BIG4_flag value for each office_key_location and merge it into the aggregated DataFrame.\n",
    "# -------------------------------\n",
    "big4_offices = df_aa_clean[['office_key_location', 'BIG4_flag']].drop_duplicates(subset=['office_key_location'])\n",
    "agg_full = agg_full.merge(big4_offices, on='office_key_location', how='left')\n",
    "\n",
    "# The final DataFrame agg_full now contains the following key variables:\n",
    "# office_key_location, FY_IC_OP, OFFICE_SIZE, TOTAL_RESTATEMENT, TOTAL_AUDIT_FEE, gap_indicator_aa,\n",
    "# OFFICE_GROWTH_NUMBERS, OFFICE_GROWTH_FEES, RESTATE_PERC, HIGH_GROWTH, BIG4_flag,\n",
    "# COMBINED_OP_INDICATOR, COMBINED_OP_RATE, and gap_indicator_aa_row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "# show(agg_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Manually check the result by office in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasgui import show\n",
    "\n",
    "def show_office_by_year(df, office_id, year):\n",
    "    df = df[df['FY_IC_OP'] == year]\n",
    "    df = df[df['office_key_location'] == office_id]\n",
    "    show(df)\n",
    "\n",
    "# show_office_by_year(df_aa_clean, \"1, Dallas, Texas\", 2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Save the AA construct panel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r\"E:\\USA auditor turnover data\\Audit Analytics data\\office-year us auditor variables from AA data.csv\"\n",
    "\n",
    "print(\"Start to save csv\")\n",
    "agg_full.to_csv(output_path, index=False)\n",
    "print(\"Csv file is saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
